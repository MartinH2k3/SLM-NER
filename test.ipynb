{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T20:42:44.014061Z",
     "start_time": "2025-04-10T20:42:43.217613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftConfig,\n",
    "    PeftModel,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline\n",
    ")\n",
    "\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "from src.utils.config_loader import load_config\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ],
   "id": "68d2944c4fbc79ab",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.bloom.modeling_bloom because of the following error (look up to see its traceback):\npartially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/transformers/utils/import_utils.py:1778\u001B[0m, in \u001B[0;36m_LazyModule._get_module\u001B[0;34m(self, module_name)\u001B[0m\n\u001B[1;32m   1777\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1778\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m importlib\u001B[38;5;241m.\u001B[39mimport_module(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m module_name, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[1;32m   1779\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/importlib/__init__.py:90\u001B[0m, in \u001B[0;36mimport_module\u001B[0;34m(name, package)\u001B[0m\n\u001B[1;32m     89\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m---> 90\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _bootstrap\u001B[38;5;241m.\u001B[39m_gcd_import(name[level:], package, level)\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1387\u001B[0m, in \u001B[0;36m_gcd_import\u001B[0;34m(name, package, level)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1360\u001B[0m, in \u001B[0;36m_find_and_load\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1331\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:935\u001B[0m, in \u001B[0;36m_load_unlocked\u001B[0;34m(spec)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap_external>:995\u001B[0m, in \u001B[0;36mexec_module\u001B[0;34m(self, module)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:488\u001B[0m, in \u001B[0;36m_call_with_frames_removed\u001B[0;34m(f, *args, **kwds)\u001B[0m\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/transformers/models/bloom/modeling_bloom.py:38\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodeling_outputs\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     32\u001B[0m     BaseModelOutputWithPastAndCrossAttentions,\n\u001B[1;32m     33\u001B[0m     CausalLMOutputWithCrossAttentions,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     36\u001B[0m     TokenClassifierOutput,\n\u001B[1;32m     37\u001B[0m )\n\u001B[0;32m---> 38\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodeling_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m PreTrainedModel\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m logging\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/transformers/modeling_utils.py:48\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mintegrations\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m PeftAdapterMixin, deepspeed_config, is_deepspeed_zero3_enabled\n\u001B[0;32m---> 48\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mloss\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mloss_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m LOSS_MAPPING\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpytorch_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (  \u001B[38;5;66;03m# noqa: F401\u001B[39;00m\n\u001B[1;32m     50\u001B[0m     Conv1D,\n\u001B[1;32m     51\u001B[0m     apply_chunking_to_forward,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     57\u001B[0m     prune_linear_layer,\n\u001B[1;32m     58\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/transformers/loss/loss_utils.py:19\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m BCEWithLogitsLoss, MSELoss\n\u001B[0;32m---> 19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mloss_deformable_detr\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mloss_for_object_detection\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ForObjectDetectionLoss, ForSegmentationLoss\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/transformers/loss/loss_deformable_detr.py:4\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnn\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimage_transforms\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m center_to_corners_format\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m is_scipy_available\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/transformers/image_transforms.py:22\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m---> 22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimage_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     23\u001B[0m     ChannelDimension,\n\u001B[1;32m     24\u001B[0m     ImageInput,\n\u001B[1;32m     25\u001B[0m     get_channel_dimension_axis,\n\u001B[1;32m     26\u001B[0m     get_image_size,\n\u001B[1;32m     27\u001B[0m     infer_channel_dimension_format,\n\u001B[1;32m     28\u001B[0m )\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ExplicitEnum, TensorType, is_jax_tensor, is_tf_tensor, is_torch_tensor\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/transformers/image_utils.py:58\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_torchvision_available():\n\u001B[0;32m---> 58\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorchvision\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtransforms\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m InterpolationMode\n\u001B[1;32m     60\u001B[0m     pil_torch_interpolation_mapping \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     61\u001B[0m         PILImageResampling\u001B[38;5;241m.\u001B[39mNEAREST: InterpolationMode\u001B[38;5;241m.\u001B[39mNEAREST,\n\u001B[1;32m     62\u001B[0m         PILImageResampling\u001B[38;5;241m.\u001B[39mBOX: InterpolationMode\u001B[38;5;241m.\u001B[39mBOX,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     66\u001B[0m         PILImageResampling\u001B[38;5;241m.\u001B[39mLANCZOS: InterpolationMode\u001B[38;5;241m.\u001B[39mLANCZOS,\n\u001B[1;32m     67\u001B[0m     }\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/torchvision/__init__.py:10\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mextension\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _HAS_OPS  \u001B[38;5;66;03m# usort:skip\u001B[39;00m\n\u001B[0;32m---> 10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorchvision\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001B[38;5;66;03m# usort:skip\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/torchvision/_meta_registrations.py:25\u001B[0m\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m wrapper\n\u001B[0;32m---> 25\u001B[0m \u001B[38;5;129m@register_meta\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mroi_align\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mmeta_roi_align\u001B[39m(\u001B[38;5;28minput\u001B[39m, rois, spatial_scale, pooled_height, pooled_width, sampling_ratio, aligned):\n\u001B[1;32m     27\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_check(rois\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m5\u001B[39m, \u001B[38;5;28;01mlambda\u001B[39;00m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrois must have shape as Tensor[K, 5]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/torchvision/_meta_registrations.py:18\u001B[0m, in \u001B[0;36mregister_meta.<locals>.wrapper\u001B[0;34m(fn)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mwrapper\u001B[39m(fn):\n\u001B[0;32m---> 18\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torchvision\u001B[38;5;241m.\u001B[39mextension\u001B[38;5;241m.\u001B[39m_has_ops():\n\u001B[1;32m     19\u001B[0m         get_meta_lib()\u001B[38;5;241m.\u001B[39mimpl(\u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mgetattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mtorchvision, op_name), overload_name), fn)\n",
      "\u001B[0;31mAttributeError\u001B[0m: partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mdatasets\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m load_dataset\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpeft\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m      5\u001B[0m     LoraConfig,\n\u001B[1;32m      6\u001B[0m     PeftConfig,\n\u001B[1;32m      7\u001B[0m     PeftModel,\n\u001B[1;32m      8\u001B[0m     prepare_model_for_kbit_training\n\u001B[1;32m      9\u001B[0m )\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtransformers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     11\u001B[0m     AutoModelForCausalLM,\n\u001B[1;32m     12\u001B[0m     AutoTokenizer,\n\u001B[1;32m     13\u001B[0m     BitsAndBytesConfig,\n\u001B[1;32m     14\u001B[0m     pipeline\n\u001B[1;32m     15\u001B[0m )\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtrl\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m SFTTrainer, SFTConfig\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/peft/__init__.py:22\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# flake8: noqa\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# There's no way to ignore \"F401 '...' imported but unused\" warnings in this\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# module, but to preserve other warnings. So, don't check this module at all.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# See the License for the specific language governing permissions and\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# limitations under the License.\u001B[39;00m\n\u001B[1;32m     20\u001B[0m __version__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m0.13.2\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mauto\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     23\u001B[0m     AutoPeftModel,\n\u001B[1;32m     24\u001B[0m     AutoPeftModelForCausalLM,\n\u001B[1;32m     25\u001B[0m     AutoPeftModelForSequenceClassification,\n\u001B[1;32m     26\u001B[0m     AutoPeftModelForSeq2SeqLM,\n\u001B[1;32m     27\u001B[0m     AutoPeftModelForTokenClassification,\n\u001B[1;32m     28\u001B[0m     AutoPeftModelForQuestionAnswering,\n\u001B[1;32m     29\u001B[0m     AutoPeftModelForFeatureExtraction,\n\u001B[1;32m     30\u001B[0m )\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmapping\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     32\u001B[0m     MODEL_TYPE_TO_PEFT_MODEL_MAPPING,\n\u001B[1;32m     33\u001B[0m     PEFT_TYPE_TO_CONFIG_MAPPING,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     36\u001B[0m     inject_adapter_in_model,\n\u001B[1;32m     37\u001B[0m )\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmixed_model\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m PeftMixedModel\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/peft/auto.py:31\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtyping\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Optional\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtransformers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     22\u001B[0m     AutoModel,\n\u001B[1;32m     23\u001B[0m     AutoModelForCausalLM,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     28\u001B[0m     AutoTokenizer,\n\u001B[1;32m     29\u001B[0m )\n\u001B[0;32m---> 31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconfig\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m PeftConfig\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmapping\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m MODEL_TYPE_TO_PEFT_MODEL_MAPPING\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpeft_model\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     34\u001B[0m     PeftModel,\n\u001B[1;32m     35\u001B[0m     PeftModelForCausalLM,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     40\u001B[0m     PeftModelForTokenClassification,\n\u001B[1;32m     41\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/peft/config.py:24\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mhuggingface_hub\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m hf_hub_download\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtransformers\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m PushToHubMixin\n\u001B[0;32m---> 24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m CONFIG_NAME, PeftType, TaskType\n\u001B[1;32m     27\u001B[0m \u001B[38;5;129m@dataclass\u001B[39m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mPeftConfigMixin\u001B[39;00m(PushToHubMixin):\n\u001B[1;32m     29\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;124;03m    This is the base configuration class for PEFT adapter models. It contains all the methods that are common to all\u001B[39;00m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;124;03m    PEFT adapter models. This class inherits from [`~transformers.utils.PushToHubMixin`] which contains the methods to\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;124;03m        peft_type (Union[[`~peft.utils.config.PeftType`], `str`]): The type of Peft method to use.\u001B[39;00m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/peft/utils/__init__.py:23\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mloftq_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m replace_lora_weights_loftq\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpeft_types\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m PeftType, TaskType\n\u001B[0;32m---> 23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mother\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     24\u001B[0m     TRANSFORMERS_MODELS_TO_PREFIX_TUNING_POSTPROCESS_MAPPING,\n\u001B[1;32m     25\u001B[0m     TRANSFORMERS_MODELS_TO_LORA_TARGET_MODULES_MAPPING,\n\u001B[1;32m     26\u001B[0m     TRANSFORMERS_MODELS_TO_ADALORA_TARGET_MODULES_MAPPING,\n\u001B[1;32m     27\u001B[0m     TRANSFORMERS_MODELS_TO_IA3_TARGET_MODULES_MAPPING,\n\u001B[1;32m     28\u001B[0m     TRANSFORMERS_MODELS_TO_IA3_FEEDFORWARD_MODULES_MAPPING,\n\u001B[1;32m     29\u001B[0m     TRANSFORMERS_MODELS_TO_LNTUNING_TARGET_MODULES_MAPPING,\n\u001B[1;32m     30\u001B[0m     TRANSFORMERS_MODELS_TO_VERA_TARGET_MODULES_MAPPING,\n\u001B[1;32m     31\u001B[0m     TRANSFORMERS_MODELS_TO_FOURIERFT_TARGET_MODULES_MAPPING,\n\u001B[1;32m     32\u001B[0m     TRANSFORMERS_MODELS_TO_VBLORA_TARGET_MODULES_MAPPING,\n\u001B[1;32m     33\u001B[0m     CONFIG_NAME,\n\u001B[1;32m     34\u001B[0m     WEIGHTS_NAME,\n\u001B[1;32m     35\u001B[0m     SAFETENSORS_WEIGHTS_NAME,\n\u001B[1;32m     36\u001B[0m     INCLUDE_LINEAR_LAYERS_SHORTHAND,\n\u001B[1;32m     37\u001B[0m     _set_trainable,\n\u001B[1;32m     38\u001B[0m     bloom_model_postprocess_past_key_value,\n\u001B[1;32m     39\u001B[0m     prepare_model_for_kbit_training,\n\u001B[1;32m     40\u001B[0m     shift_tokens_right,\n\u001B[1;32m     41\u001B[0m     transpose,\n\u001B[1;32m     42\u001B[0m     _get_batch_size,\n\u001B[1;32m     43\u001B[0m     _get_submodules,\n\u001B[1;32m     44\u001B[0m     _set_adapter,\n\u001B[1;32m     45\u001B[0m     _freeze_adapter,\n\u001B[1;32m     46\u001B[0m     ModulesToSaveWrapper,\n\u001B[1;32m     47\u001B[0m     _prepare_prompt_learning_config,\n\u001B[1;32m     48\u001B[0m     _is_valid_match,\n\u001B[1;32m     49\u001B[0m     infer_device,\n\u001B[1;32m     50\u001B[0m     get_auto_gptq_quant_linear,\n\u001B[1;32m     51\u001B[0m     get_quantization_config,\n\u001B[1;32m     52\u001B[0m     id_tensor_storage,\n\u001B[1;32m     53\u001B[0m     cast_mixed_precision_params,\n\u001B[1;32m     54\u001B[0m )\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msave_and_load\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m get_peft_model_state_dict, set_peft_model_state_dict, load_peft_weights\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/peft/utils/other.py:33\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msafetensors\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m storage_ptr, storage_size\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimport_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m is_auto_gptq_available, is_torch_tpu_available\n\u001B[0;32m---> 33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconstants\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     34\u001B[0m     CONFIG_NAME,\n\u001B[1;32m     35\u001B[0m     EMBEDDING_LAYER_NAMES,\n\u001B[1;32m     36\u001B[0m     INCLUDE_LINEAR_LAYERS_SHORTHAND,\n\u001B[1;32m     37\u001B[0m     SAFETENSORS_WEIGHTS_NAME,\n\u001B[1;32m     38\u001B[0m     TRANSFORMERS_MODELS_TO_ADALORA_TARGET_MODULES_MAPPING,\n\u001B[1;32m     39\u001B[0m     TRANSFORMERS_MODELS_TO_FOURIERFT_TARGET_MODULES_MAPPING,\n\u001B[1;32m     40\u001B[0m     TRANSFORMERS_MODELS_TO_IA3_FEEDFORWARD_MODULES_MAPPING,\n\u001B[1;32m     41\u001B[0m     TRANSFORMERS_MODELS_TO_IA3_TARGET_MODULES_MAPPING,\n\u001B[1;32m     42\u001B[0m     TRANSFORMERS_MODELS_TO_LNTUNING_TARGET_MODULES_MAPPING,\n\u001B[1;32m     43\u001B[0m     TRANSFORMERS_MODELS_TO_LORA_TARGET_MODULES_MAPPING,\n\u001B[1;32m     44\u001B[0m     TRANSFORMERS_MODELS_TO_PREFIX_TUNING_POSTPROCESS_MAPPING,\n\u001B[1;32m     45\u001B[0m     TRANSFORMERS_MODELS_TO_VBLORA_TARGET_MODULES_MAPPING,\n\u001B[1;32m     46\u001B[0m     TRANSFORMERS_MODELS_TO_VERA_TARGET_MODULES_MAPPING,\n\u001B[1;32m     47\u001B[0m     WEIGHTS_NAME,\n\u001B[1;32m     48\u001B[0m     bloom_model_postprocess_past_key_value,\n\u001B[1;32m     49\u001B[0m     starcoder_model_postprocess_past_key_value,\n\u001B[1;32m     50\u001B[0m )\n\u001B[1;32m     53\u001B[0m mlu_available \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m version\u001B[38;5;241m.\u001B[39mparse(accelerate\u001B[38;5;241m.\u001B[39m__version__) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m version\u001B[38;5;241m.\u001B[39mparse(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m0.29.0\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/peft/utils/constants.py:16\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Copyright 2023-present the HuggingFace Inc. team.\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# See the License for the specific language governing permissions and\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# limitations under the License.\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m---> 16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtransformers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m BloomPreTrainedModel\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# needed for prefix-tuning of bloom model\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mbloom_model_postprocess_past_key_value\u001B[39m(past_key_values):\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1412\u001B[0m, in \u001B[0;36m_handle_fromlist\u001B[0;34m(module, fromlist, import_, recursive)\u001B[0m\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/transformers/utils/import_utils.py:1767\u001B[0m, in \u001B[0;36m_LazyModule.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1765\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_class_to_module\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m   1766\u001B[0m     module \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_module(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_class_to_module[name])\n\u001B[0;32m-> 1767\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(module, name)\n\u001B[1;32m   1768\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_modules:\n\u001B[1;32m   1769\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_module(name)\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/transformers/utils/import_utils.py:1766\u001B[0m, in \u001B[0;36m_LazyModule.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1764\u001B[0m     value \u001B[38;5;241m=\u001B[39m Placeholder\n\u001B[1;32m   1765\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_class_to_module\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m-> 1766\u001B[0m     module \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_module(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_class_to_module[name])\n\u001B[1;32m   1767\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(module, name)\n\u001B[1;32m   1768\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_modules:\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/transformers/utils/import_utils.py:1780\u001B[0m, in \u001B[0;36m_LazyModule._get_module\u001B[0;34m(self, module_name)\u001B[0m\n\u001B[1;32m   1778\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m importlib\u001B[38;5;241m.\u001B[39mimport_module(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m module_name, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[1;32m   1779\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m-> 1780\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m   1781\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to import \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodule_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m because of the following error (look up to see its\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1782\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m traceback):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1783\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01me\u001B[39;00m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Failed to import transformers.models.bloom.modeling_bloom because of the following error (look up to see its traceback):\npartially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "config = load_config()\n",
    "train_dataset_path = config.get(\"train_dataset_path\")\n",
    "test_dataset_path = config.get(\"test_dataset_path\")\n",
    "dev_dataset_path = config.get(\"dev_dataset_path\")\n",
    "system_prompt_path = config.get(\"system_prompt_path\")\n",
    "checkpoint_path = config.get(\"checkpoint_path\")"
   ],
   "id": "d75677aab45bddda"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "raw_train = load_dataset(\"json\", data_files=train_dataset_path, download_mode=\"force_redownload\")[\"train\"]\n",
    "raw_test = load_dataset(\"json\", data_files=test_dataset_path, download_mode=\"force_redownload\")[\"train\"]\n",
    "raw_dev = load_dataset(\"json\", data_files=dev_dataset_path, download_mode=\"force_redownload\")[\"train\"]"
   ],
   "id": "54629bd7f5f45904"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6856c7d72d05d86a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

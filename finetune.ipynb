{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa815db520427de8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T15:37:22.447883Z",
     "start_time": "2024-11-21T15:37:18.516367Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig\n",
    "import torch\n",
    "import transformers\n",
    "from trl import SFTTrainer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3543a2f3-8e26-4ac8-9e5b-1859e209f115",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config = {\n",
    "    \"bf16\": True,\n",
    "    \"do_eval\": False,\n",
    "    \"learning_rate\": 5.0e-06,\n",
    "    \"log_level\": \"info\",\n",
    "    \"logging_steps\": 20,\n",
    "    \"logging_strategy\": \"steps\",\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"max_steps\": 120,\n",
    "    \"output_dir\": \"./checkpoint_dir\",\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"per_device_eval_batch_size\": 4,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"remove_unused_columns\": True,\n",
    "    \"save_steps\": 100,\n",
    "    \"save_total_limit\": 1,\n",
    "    \"seed\": 0,\n",
    "    \"gradient_checkpointing\": True,\n",
    "    \"gradient_checkpointing_kwargs\":{\"use_reentrant\": False},\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"warmup_ratio\": 0.2,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8367c3b0-1428-44a3-99ea-4d4088c1edaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = {\n",
    "    \"r\": 16,\n",
    "    \"lora_alpha\": 32,\n",
    "    \"lora_dropout\": 0.05,\n",
    "    \"bias\": \"none\",\n",
    "    \"task_type\": \"CAUSAL_LM\",\n",
    "    \"target_modules\": \"all-linear\",\n",
    "    \"modules_to_save\": None,\n",
    "}\n",
    "train_conf = TrainingArguments(**training_config)\n",
    "peft_conf = LoraConfig(**peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99a32741-9dfe-41b7-9e3e-6545dfbc7583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 18:11:56 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1 distributed training: True, 16-bits training: False\n",
      "2024-11-21 18:11:56 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "average_tokens_across_devices=False,\n",
      "batch_eval_metrics=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_on_start=False,\n",
      "eval_steps=None,\n",
      "eval_strategy=IntervalStrategy.NO,\n",
      "eval_use_gather_object=False,\n",
      "evaluation_strategy=None,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=True,\n",
      "gradient_checkpointing_kwargs={'use_reentrant': False},\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_for_metrics=[],\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-06,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=info,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./checkpoint_dir/runs/Nov21_18-11-06_James,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=20,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=SchedulerType.COSINE,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1,\n",
      "optim=OptimizerNames.ADAMW_TORCH,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=./checkpoint_dir,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./checkpoint_dir,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=100,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=1,\n",
      "seed=0,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=None,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torch_empty_cache_steps=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_liger_kernel=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.2,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "2024-11-21 18:11:56 - INFO - __main__ - PEFT parameters LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='CAUSAL_LM', inference_mode=False, r=16, target_modules='all-linear', lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False))\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "log_level = train_conf.get_process_log_level()\n",
    "logger.setLevel(log_level)\n",
    "datasets.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.enable_default_handler()\n",
    "transformers.utils.logging.enable_explicit_format()\n",
    "\n",
    "# Log on each process a small summary\n",
    "logger.warning(\n",
    "    f\"Process rank: {train_conf.local_rank}, device: {train_conf.device}, n_gpu: {train_conf.n_gpu}\"\n",
    "    + f\" distributed training: {bool(train_conf.local_rank != -1)}, 16-bits training: {train_conf.fp16}\"\n",
    ")\n",
    "logger.info(f\"Training/evaluation parameters {train_conf}\")\n",
    "logger.info(f\"PEFT parameters {peft_conf}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7a80cf93-b1cd-48be-ad64-8ca12bb15a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:679] 2024-11-21 20:57:10,500 >> loading configuration file config.json from cache at /home/martinh2k3/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/0a67737cc96d2554230f90338b163bc6380a2a85/config.json\n",
      "[INFO|configuration_utils.py:679] 2024-11-21 20:57:10,691 >> loading configuration file config.json from cache at /home/martinh2k3/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/0a67737cc96d2554230f90338b163bc6380a2a85/config.json\n",
      "[INFO|configuration_utils.py:746] 2024-11-21 20:57:10,693 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"microsoft/Phi-3-mini-4k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3937] 2024-11-21 20:57:10,891 >> loading weights file model.safetensors from cache at /home/martinh2k3/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/0a67737cc96d2554230f90338b163bc6380a2a85/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:1670] 2024-11-21 20:57:10,895 >> Instantiating Phi3ForCausalLM model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:1096] 2024-11-21 20:57:10,897 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"use_cache\": false\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa6925747dc54b76a65107b185ea0c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:4800] 2024-11-21 20:57:11,479 >> All model checkpoint weights were used when initializing Phi3ForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4808] 2024-11-21 20:57:11,480 >> All the weights of Phi3ForCausalLM were initialized from the model checkpoint at microsoft/Phi-3-mini-4k-instruct.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Phi3ForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:1051] 2024-11-21 20:57:11,654 >> loading configuration file generation_config.json from cache at /home/martinh2k3/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/0a67737cc96d2554230f90338b163bc6380a2a85/generation_config.json\n",
      "[INFO|configuration_utils.py:1096] 2024-11-21 20:57:11,655 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": [\n",
      "    32000,\n",
      "    32001,\n",
      "    32007\n",
      "  ],\n",
      "  \"pad_token_id\": 32000\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2211] 2024-11-21 20:57:11,820 >> loading file tokenizer.model from cache at /home/martinh2k3/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/0a67737cc96d2554230f90338b163bc6380a2a85/tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2211] 2024-11-21 20:57:11,822 >> loading file tokenizer.json from cache at /home/martinh2k3/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/0a67737cc96d2554230f90338b163bc6380a2a85/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2211] 2024-11-21 20:57:11,823 >> loading file added_tokens.json from cache at /home/martinh2k3/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/0a67737cc96d2554230f90338b163bc6380a2a85/added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2211] 2024-11-21 20:57:11,824 >> loading file special_tokens_map.json from cache at /home/martinh2k3/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/0a67737cc96d2554230f90338b163bc6380a2a85/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2211] 2024-11-21 20:57:11,825 >> loading file tokenizer_config.json from cache at /home/martinh2k3/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/0a67737cc96d2554230f90338b163bc6380a2a85/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2475] 2024-11-21 20:57:11,942 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "# checkpoint_path = \"microsoft/Phi-3-mini-128k-instruct\"\n",
    "model_kwargs = dict(\n",
    "    use_cache=False,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=None\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint_path, **model_kwargs)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
    "tokenizer.model_max_length = 2048\n",
    "tokenizer.pad_token = tokenizer.unk_token  # use unk rather than eos token to prevent endless generation\n",
    "tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "tokenizer.padding_side = 'right'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfcb4ed-a220-4abe-bfd3-c360addd95ae",
   "metadata": {},
   "source": [
    "Load datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0ed436d0-22f3-4669-8ede-d21bbe979823",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T18:13:10.747842Z",
     "start_time": "2024-11-21T18:13:10.684576Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-a428603bbc82149e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:05 - INFO - datasets.builder - Using custom data configuration default-a428603bbc82149e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset Infos from /home/martinh2k3/anaconda3/envs/bp/lib/python3.12/site-packages/datasets/packaged_modules/json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:05 - INFO - datasets.info - Loading Dataset Infos from /home/martinh2k3/anaconda3/envs/bp/lib/python3.12/site-packages/datasets/packaged_modules/json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating dataset json (/home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:05 - INFO - datasets.builder - Generating dataset json (/home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:05 - INFO - datasets.builder - Downloading and preparing dataset json/default to /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading took 0.0 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:05 - INFO - datasets.download.download_manager - Downloading took 0.0 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checksum Computation took 0.0 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:05 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:05 - INFO - datasets.builder - Generating train split\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5229d5312dd476a9172cbf18856d9aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to verify splits sizes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:05 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:05 - INFO - datasets.builder - Dataset json downloaded and prepared to /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-716ccb4327edc3cc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:05 - INFO - datasets.builder - Using custom data configuration default-716ccb4327edc3cc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset Infos from /home/martinh2k3/anaconda3/envs/bp/lib/python3.12/site-packages/datasets/packaged_modules/json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:05 - INFO - datasets.info - Loading Dataset Infos from /home/martinh2k3/anaconda3/envs/bp/lib/python3.12/site-packages/datasets/packaged_modules/json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating dataset json (/home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:05 - INFO - datasets.builder - Generating dataset json (/home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:05 - INFO - datasets.builder - Downloading and preparing dataset json/default to /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading took 0.0 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:05 - INFO - datasets.download.download_manager - Downloading took 0.0 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checksum Computation took 0.0 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:05 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:05 - INFO - datasets.builder - Generating train split\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b373e45982964eb2b30f8ce01eca9b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to verify splits sizes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:05 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:05 - INFO - datasets.builder - Dataset json downloaded and prepared to /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-0d3ee0f7bc793fac\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:05 - INFO - datasets.builder - Using custom data configuration default-0d3ee0f7bc793fac\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset Infos from /home/martinh2k3/anaconda3/envs/bp/lib/python3.12/site-packages/datasets/packaged_modules/json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:05 - INFO - datasets.info - Loading Dataset Infos from /home/martinh2k3/anaconda3/envs/bp/lib/python3.12/site-packages/datasets/packaged_modules/json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating dataset json (/home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:05 - INFO - datasets.builder - Generating dataset json (/home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:05 - INFO - datasets.builder - Downloading and preparing dataset json/default to /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading took 0.0 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:05 - INFO - datasets.download.download_manager - Downloading took 0.0 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checksum Computation took 0.0 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:05 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:05 - INFO - datasets.builder - Generating train split\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80997ab273ec45168c88ab8f092c60d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to verify splits sizes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:05 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:05 - INFO - datasets.builder - Dataset json downloaded and prepared to /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "raw_train = datasets.load_dataset(\"json\", data_files=\"./data/NCBItrainset_corpus.json\", download_mode=\"force_redownload\")[\"train\"]\n",
    "raw_test = datasets.load_dataset(\"json\", data_files=\"./data/NCBItestset_corpus.json\", download_mode=\"force_redownload\")[\"train\"]\n",
    "raw_dev = datasets.load_dataset(\"json\", data_files=\"./data/NCBIdevelopset_corpus.json\", download_mode=\"force_redownload\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "dd7ba55e-fbd1-4029-a64b-bfcd4585bf4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'system': 'Please identify all the named entities mentioned in the input sentence provided below. Use only the categories: SpecificDisease, DiseaseClass, CompositeMention, and Modifier. Remember, some terms might refer to broader disease classes, while others are specific diseases or composite mentions involving multiple diseases. You should only output the results in JSON format, following a similar structure to the example result provided.\\n\\n    Example sentence and results:\\n    \"A common human skin tumour is caused by activating mutations in beta-catenin.\"\\n\\n    \"\\\\\"Results\\\\\": [\\n        { \\\\\"category\\\\\": \\\\\"DiseaseClass\\\\\", \\\\\"entity\\\\\": \\\\\"skin tumour\\\\\" }\\n    ]\"\\n    ',\n",
       " 'user': 'A common human skin tumour is caused by activating mutations in beta-catenin.WNT signalling orchestrates a number of developmental programs.In response to this stimulus, cytoplasmic beta-catenin (encoded by CTNNB1) is stabilized, enabling downstream transcriptional activation by members of the LEF/TCF family.',\n",
       " 'assistant': '[\"{\\\\\"category\\\\\": DiseaseClass, \\\\\"entity\\\\\": skin tumour}, \"]'}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fe7bd3-193d-4045-abbd-cfef805e3a54",
   "metadata": {},
   "source": [
    "Tokenize input into correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9a098ab7-aa0a-4d8b-bce0-56a4f7b5af3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #0 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00000_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:18 - INFO - datasets.arrow_dataset - Process #0 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00000_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #1 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00001_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:18 - INFO - datasets.arrow_dataset - Process #1 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00001_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #2 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00002_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:18 - INFO - datasets.arrow_dataset - Process #2 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00002_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #3 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00003_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:18 - INFO - datasets.arrow_dataset - Process #3 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00003_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #4 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00004_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:18 - INFO - datasets.arrow_dataset - Process #4 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00004_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #5 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00005_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:18 - INFO - datasets.arrow_dataset - Process #5 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00005_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #6 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00006_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:18 - INFO - datasets.arrow_dataset - Process #6 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00006_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #7 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00007_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:18 - INFO - datasets.arrow_dataset - Process #7 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00007_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #8 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00008_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:18 - INFO - datasets.arrow_dataset - Process #8 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00008_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #9 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00009_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:18 - INFO - datasets.arrow_dataset - Process #9 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00009_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Spawning 10 processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:18 - INFO - datasets.arrow_dataset - Spawning 10 processes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c9810432564bfa9ce8f51e6e47137c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train_sft (num_proc=10):   0%|          | 0/2061 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00000_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:18 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00000_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00001_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:18 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00001_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00002_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:18 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00002_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00003_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:18 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00003_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00004_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:18 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00004_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00005_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:18 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00005_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00006_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:18 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00006_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00007_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:18 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00007_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00008_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:18 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00008_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00009_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:18 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2991b260959a2bd0_00009_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Concatenating 10 shards\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Concatenating 10 shards\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #0 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00000_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Process #0 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00000_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #1 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00001_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Process #1 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00001_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #2 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00002_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Process #2 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00002_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #3 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00003_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Process #3 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00003_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #4 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00004_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Process #4 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00004_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #5 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00005_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Process #5 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00005_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #6 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00006_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Process #6 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00006_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #7 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00007_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Process #7 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00007_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #8 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00008_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Process #8 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00008_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #9 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00009_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Process #9 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00009_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Spawning 10 processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Spawning 10 processes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4978d4aabdba4fa79025c17e07f6a645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train_sft (num_proc=10):   0%|          | 0/382 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00000_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00000_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00001_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00001_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00002_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00002_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00003_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00003_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00004_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00004_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00005_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00005_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00006_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00006_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00007_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00007_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00009_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00009_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00008_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9a7294531412b931_00008_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Concatenating 10 shards\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Concatenating 10 shards\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #0 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00000_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Process #0 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00000_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #1 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00001_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Process #1 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00001_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #2 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00002_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Process #2 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00002_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #3 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00003_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Process #3 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00003_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #4 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00004_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Process #4 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00004_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #5 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00005_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Process #5 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00005_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #6 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00006_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Process #6 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00006_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #7 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00007_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Process #7 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00007_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #8 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00008_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Process #8 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00008_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #9 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00009_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Process #9 will write at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00009_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Spawning 10 processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:19 - INFO - datasets.arrow_dataset - Spawning 10 processes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c5cdd9449eb46c4aeb67640f4b79a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train_sft (num_proc=10):   0%|          | 0/344 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00000_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:20 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00000_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00001_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:20 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00001_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00002_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:20 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00002_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00003_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:20 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00003_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00004_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:20 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00004_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00005_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:20 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00005_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00006_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:20 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00006_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00007_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:20 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00007_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00008_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:20 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00008_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00009_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:20 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-0d3ee0f7bc793fac/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-73136685d4784318_00009_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Concatenating 10 shards\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:20 - INFO - datasets.arrow_dataset - Concatenating 10 shards\n"
     ]
    }
   ],
   "source": [
    "def apply_chat_template(example, tokenizer):\n",
    "    \"\"\"\n",
    "    Convert the system, input, and output fields into a formatted chat-like text.\n",
    "    \"\"\"\n",
    "    # Combine the fields into a structured chat format\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": example[\"system\"] if example[\"system\"] else \"\"},\n",
    "        {\"role\": \"user\", \"content\": example[\"user\"] if example[\"user\"] else \"\"},\n",
    "        {\"role\": \"assistant\", \"content\": example[\"assistant\"] if example[\"assistant\"] else \"\"}\n",
    "    ]\n",
    "    # Use the tokenizer's chat template to create formatted text\n",
    "    example[\"text\"] = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=False\n",
    "    )\n",
    "    return example\n",
    "\n",
    "column_names = list(raw_train.features)\n",
    "\n",
    "# Apply processing to each dataset\n",
    "processed_train = raw_train.map(\n",
    "    apply_chat_template,\n",
    "    fn_kwargs={\"tokenizer\": tokenizer},\n",
    "    num_proc=10,\n",
    "    remove_columns=column_names,\n",
    "    desc=\"Applying chat template to train_sft\",\n",
    ")\n",
    "processed_test = raw_test.map(\n",
    "    apply_chat_template,\n",
    "    fn_kwargs={\"tokenizer\": tokenizer},\n",
    "    num_proc=10,\n",
    "    remove_columns=column_names,\n",
    "    desc=\"Applying chat template to train_sft\",\n",
    ")\n",
    "processed_dev = raw_dev.map(\n",
    "    apply_chat_template,\n",
    "    fn_kwargs={\"tokenizer\": tokenizer},\n",
    "    num_proc=10,\n",
    "    remove_columns=column_names,\n",
    "    desc=\"Applying chat template to train_sft\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a0f7ad9d-f6fd-4eaf-b62a-fa92d17232e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|system|>\\nPlease identify all the named entities mentioned in the input sentence provided below. Use only the categories: SpecificDisease, DiseaseClass, CompositeMention, and Modifier. Remember, some terms might refer to broader disease classes, while others are specific diseases or composite mentions involving multiple diseases. You should only output the results in JSON format, following a similar structure to the example result provided.\\n\\n    Example sentence and results:\\n    \"A common human skin tumour is caused by activating mutations in beta-catenin.\"\\n\\n    \"\\\\\"Results\\\\\": [\\n        { \\\\\"category\\\\\": \\\\\"DiseaseClass\\\\\", \\\\\"entity\\\\\": \\\\\"skin tumour\\\\\" }\\n    ]\"\\n    <|end|>\\n<|user|>\\nFabry disease (FD) (angiokeratoma corporis diffusum) is an X-linked inborn error of glycosphingolipid metabolism caused by defects in the lysosomal alpha-galactosidase A gene (GLA).The enzymatic defect leads to the systemic accumulation of neutral glycosphingolipids with terminal alpha-galactosyl moieties.<|end|>\\n<|assistant|>\\n[\"{\\\\\"category\\\\\": SpecificDisease, \\\\\"entity\\\\\": Fabry disease}, \"\"{\\\\\"category\\\\\": SpecificDisease, \\\\\"entity\\\\\": FD}, \"\"{\\\\\"category\\\\\": SpecificDisease, \\\\\"entity\\\\\": angiokeratoma corporis diffusum}, \"\"{\\\\\"category\\\\\": DiseaseClass, \\\\\"entity\\\\\": X-linked inborn error of glycosphingolipid metabolism}, \"]<|end|>\\n<|endoftext|>'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_train[89][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c6b09e33-61b9-4527-974a-3e7b88b185e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martinh2k3/anaconda3/envs/bp/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field. Will not be supported from version '0.13.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "[INFO|training_args.py:2169] 2024-11-21 22:58:48,645 >> PyTorch: setting up devices\n",
      "/home/martinh2k3/anaconda3/envs/bp/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/home/martinh2k3/anaconda3/envs/bp/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2157b8e5a1854a419719b8b7e6e69981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2061 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-4cb83d9e7887f779.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:50 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-a428603bbc82149e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-4cb83d9e7887f779.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b72ea06347e04fbcacab02f9964dcd6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/382 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-890c869d430509b9.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:58:51 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/martinh2k3/.cache/huggingface/datasets/json/default-716ccb4327edc3cc/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-890c869d430509b9.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:699] 2024-11-21 22:58:51,185 >> Using auto half precision backend\n",
      "[INFO|trainer.py:2314] 2024-11-21 22:58:52,152 >> ***** Running training *****\n",
      "[INFO|trainer.py:2315] 2024-11-21 22:58:52,153 >>   Num examples = 2,061\n",
      "[INFO|trainer.py:2316] 2024-11-21 22:58:52,154 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:2317] 2024-11-21 22:58:52,155 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:2320] 2024-11-21 22:58:52,155 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:2321] 2024-11-21 22:58:52,156 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:2322] 2024-11-21 22:58:52,157 >>   Total optimization steps = 516\n",
      "[INFO|trainer.py:2323] 2024-11-21 22:58:52,160 >>   Number of trainable parameters = 25,165,824\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='516' max='516' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [516/516 03:14, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.520300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.220600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.095100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.513200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.001800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3812] 2024-11-21 22:59:29,811 >> Saving model checkpoint to ./checkpoint_dir/checkpoint-100\n",
      "[INFO|configuration_utils.py:679] 2024-11-21 22:59:30,240 >> loading configuration file config.json from cache at /home/martinh2k3/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/0a67737cc96d2554230f90338b163bc6380a2a85/config.json\n",
      "[INFO|configuration_utils.py:746] 2024-11-21 22:59:30,244 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2646] 2024-11-21 22:59:30,749 >> tokenizer config file saved in ./checkpoint_dir/checkpoint-100/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2655] 2024-11-21 22:59:30,757 >> Special tokens file saved in ./checkpoint_dir/checkpoint-100/special_tokens_map.json\n",
      "[INFO|trainer.py:3904] 2024-11-21 22:59:31,095 >> Deleting older checkpoint [checkpoint_dir/checkpoint-100] due to args.save_total_limit\n",
      "[INFO|trainer.py:3812] 2024-11-21 23:00:05,975 >> Saving model checkpoint to ./checkpoint_dir/checkpoint-200\n",
      "[INFO|configuration_utils.py:679] 2024-11-21 23:00:06,759 >> loading configuration file config.json from cache at /home/martinh2k3/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/0a67737cc96d2554230f90338b163bc6380a2a85/config.json\n",
      "[INFO|configuration_utils.py:746] 2024-11-21 23:00:06,761 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2646] 2024-11-21 23:00:06,886 >> tokenizer config file saved in ./checkpoint_dir/checkpoint-200/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2655] 2024-11-21 23:00:06,888 >> Special tokens file saved in ./checkpoint_dir/checkpoint-200/special_tokens_map.json\n",
      "[INFO|trainer.py:3904] 2024-11-21 23:00:07,211 >> Deleting older checkpoint [checkpoint_dir/checkpoint-200] due to args.save_total_limit\n",
      "[INFO|trainer.py:3812] 2024-11-21 23:00:44,721 >> Saving model checkpoint to ./checkpoint_dir/checkpoint-300\n",
      "[INFO|configuration_utils.py:679] 2024-11-21 23:00:45,066 >> loading configuration file config.json from cache at /home/martinh2k3/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/0a67737cc96d2554230f90338b163bc6380a2a85/config.json\n",
      "[INFO|configuration_utils.py:746] 2024-11-21 23:00:45,067 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2646] 2024-11-21 23:00:45,194 >> tokenizer config file saved in ./checkpoint_dir/checkpoint-300/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2655] 2024-11-21 23:00:45,195 >> Special tokens file saved in ./checkpoint_dir/checkpoint-300/special_tokens_map.json\n",
      "[INFO|trainer.py:3904] 2024-11-21 23:00:45,516 >> Deleting older checkpoint [checkpoint_dir/checkpoint-300] due to args.save_total_limit\n",
      "[INFO|trainer.py:3812] 2024-11-21 23:01:22,897 >> Saving model checkpoint to ./checkpoint_dir/checkpoint-400\n",
      "[INFO|configuration_utils.py:679] 2024-11-21 23:01:23,448 >> loading configuration file config.json from cache at /home/martinh2k3/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/0a67737cc96d2554230f90338b163bc6380a2a85/config.json\n",
      "[INFO|configuration_utils.py:746] 2024-11-21 23:01:23,452 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2646] 2024-11-21 23:01:23,588 >> tokenizer config file saved in ./checkpoint_dir/checkpoint-400/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2655] 2024-11-21 23:01:23,589 >> Special tokens file saved in ./checkpoint_dir/checkpoint-400/special_tokens_map.json\n",
      "[INFO|trainer.py:3904] 2024-11-21 23:01:23,913 >> Deleting older checkpoint [checkpoint_dir/checkpoint-400] due to args.save_total_limit\n",
      "[INFO|trainer.py:3812] 2024-11-21 23:02:01,966 >> Saving model checkpoint to ./checkpoint_dir/checkpoint-500\n",
      "[INFO|configuration_utils.py:679] 2024-11-21 23:02:02,297 >> loading configuration file config.json from cache at /home/martinh2k3/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/0a67737cc96d2554230f90338b163bc6380a2a85/config.json\n",
      "[INFO|configuration_utils.py:746] 2024-11-21 23:02:02,300 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2646] 2024-11-21 23:02:02,429 >> tokenizer config file saved in ./checkpoint_dir/checkpoint-500/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2655] 2024-11-21 23:02:02,430 >> Special tokens file saved in ./checkpoint_dir/checkpoint-500/special_tokens_map.json\n",
      "[INFO|trainer.py:3904] 2024-11-21 23:02:02,745 >> Deleting older checkpoint [checkpoint_dir/checkpoint-500] due to args.save_total_limit\n",
      "[INFO|trainer.py:3812] 2024-11-21 23:02:06,469 >> Saving model checkpoint to ./checkpoint_dir/checkpoint-516\n",
      "[INFO|configuration_utils.py:679] 2024-11-21 23:02:06,807 >> loading configuration file config.json from cache at /home/martinh2k3/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/0a67737cc96d2554230f90338b163bc6380a2a85/config.json\n",
      "[INFO|configuration_utils.py:746] 2024-11-21 23:02:06,810 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2646] 2024-11-21 23:02:07,007 >> tokenizer config file saved in ./checkpoint_dir/checkpoint-516/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2655] 2024-11-21 23:02:07,008 >> Special tokens file saved in ./checkpoint_dir/checkpoint-516/special_tokens_map.json\n",
      "[INFO|trainer.py:2591] 2024-11-21 23:02:07,340 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =        1.0\n",
      "  total_flos               =   172647GF\n",
      "  train_loss               =     0.6782\n",
      "  train_runtime            = 0:03:15.17\n",
      "  train_samples_per_second =      10.56\n",
      "  train_steps_per_second   =      2.644\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=train_conf,\n",
    "    peft_config=peft_conf,\n",
    "    train_dataset=processed_train,\n",
    "    eval_dataset=processed_test,\n",
    "    max_seq_length=4,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "train_result = trainer.train()\n",
    "metrics = train_result.metrics\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "trainer.save_metrics(\"train\", metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c422d1fa-1e70-4dbb-b88f-2372b73550a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Phi3Config' object has no attribute 'attention_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_type\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/transformers/configuration_utils.py:205\u001b[0m, in \u001b[0;36mPretrainedConfig.__getattribute__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattribute_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattribute_map\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    204\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattribute_map\u001b[39m\u001b[38;5;124m\"\u001b[39m)[key]\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Phi3Config' object has no attribute 'attention_type'"
     ]
    }
   ],
   "source": [
    "print(model.config.attention_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d6defbd6-9680-41c5-b099-a232f7cd1e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phi3Config {\n",
      "  \"_attn_implementation_autoset\": true,\n",
      "  \"_name_or_path\": \"microsoft/Phi-3-mini-4k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6ef1d3af-d5e9-4056-8a75-260067cf7c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:414] 2024-11-21 21:16:13,310 >> Configuration saved in ./trained_model/config.json\n",
      "[INFO|configuration_utils.py:865] 2024-11-21 21:16:13,314 >> Configuration saved in ./trained_model/generation_config.json\n",
      "[INFO|modeling_utils.py:3043] 2024-11-21 21:16:21,510 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./trained_model/model.safetensors.index.json.\n",
      "[INFO|tokenization_utils_base.py:2646] 2024-11-21 21:16:21,512 >> tokenizer config file saved in ./trained_model/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2655] 2024-11-21 21:16:21,513 >> Special tokens file saved in ./trained_model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./trained_model/tokenizer_config.json',\n",
       " './trained_model/special_tokens_map.json',\n",
       " './trained_model/tokenizer.json')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./trained_model\")\n",
    "tokenizer.save_pretrained(\"./trained_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0cdc6672-2ee2-4bed-8118-698759101559",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = raw_train[0]['system'][:-1]+\"\\n\"+\"Somatic-cell selection is a major determinant of the blood-cell phenotype in heterozygotes for glucose-6-phosphate dehydrogenase mutations causing severe enzyme deficiency.X-chromosome inactivation in mammals is regarded as an essentially random process, but the resulting somatic-cell mosaicism creates the opportunity for cell selection.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b9dded35-6eeb-4189-97df-7d3acf86e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_inference(user_input: str, system_prompt=None):\n",
    "    if not system_prompt:\n",
    "        system_prompt = \"Please identify all the named entities mentioned in the input sentence provided below. Use only the categories: SpecificDisease, DiseaseClass, CompositeMention, and Modifier. Remember, some terms might refer to broader disease classes, while others are specific diseases or composite mentions involving multiple diseases. You should only output the results in JSON format, following a similar structure to the example result provided.\\n\\nExample sentence and results:\\n\\\"A common human skin tumour is caused by activating mutations in beta-catenin.\\\"\\n\\n\\\"Results\\\": [\\n{ \\\"category\\\": \\\"DiseaseClass\\\", \\\"entity\\\": \\\"skin tumour\\\" }\\n]\\n\"\n",
    "    prompt_data = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_input}\n",
    "    ]\n",
    "    return  tokenizer.apply_chat_template(\n",
    "        prompt_data, tokenize=False, add_generation_prompt=\"<|assistant|>\" \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c4b36dd6-b711-4784-90d3-581fea1125b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|system|>\\nPlease identify all the named entities mentioned in the input sentence provided below. Use only the categories: SpecificDisease, DiseaseClass, CompositeMention, and Modifier. Remember, some terms might refer to broader disease classes, while others are specific diseases or composite mentions involving multiple diseases. You should only output the results in JSON format, following a similar structure to the example result provided.\\n\\nExample sentence and results:\\n\"A common human skin tumour is caused by activating mutations in beta-catenin.\"\\n\\n\"Results\": [\\n{ \"category\": \"DiseaseClass\", \"entity\": \"skin tumour\" }\\n]\\n<|end|>\\n<|user|>\\nSomatic-cell selection is a major determinant of the blood-cell phenotype in heterozygotes for glucose-6-phosphate dehydrogenase mutations causing severe enzyme deficiency.X-chromosome inactivation in mammals is regarded as an essentially random process, but the resulting somatic-cell mosaicism creates the opportunity for cell selection.<|end|>\\n<|assistant|>\\n'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_input = prepare_for_inference(\"Somatic-cell selection is a major determinant of the blood-cell phenotype in heterozygotes for glucose-6-phosphate dehydrogenase mutations causing severe enzyme deficiency.X-chromosome inactivation in mammals is regarded as an essentially random process, but the resulting somatic-cell mosaicism creates the opportunity for cell selection.\")\n",
    "processed_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cc11fd00-2b42-45a3-b74e-a6ef49a510c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please identify all the named entities mentioned in the input sentence provided below. Use only the categories: SpecificDisease, DiseaseClass, CompositeMention, and Modifier. Remember, some terms might refer to broader disease classes, while others are specific diseases or composite mentions involving multiple diseases. You should only output the results in JSON format, following a similar structure to the example result provided.\n",
      "\n",
      "Example sentence and results:\n",
      "\"A common human skin tumour is caused by activating mutations in beta-catenin.\"\n",
      "\n",
      "\"Results\": [\n",
      "{ \"category\": \"DiseaseClass\", \"entity\": \"skin tumour\" }\n",
      "]\n",
      " Somatic-cell selection is a major determinant of the blood-cell phenotype in heterozygotes for glucose-6-phosphate dehydrogenase mutations causing severe enzyme deficiency.X-chromosome inactivation in mammals is regarded as an essentially random process, but the resulting somatic-cell mosaicism creates the opportunity for cell selection. \"Results\": [\n",
      "{ \"category\": \"DiseaseClass\", \"entity\": \"glucose-6-phosphate dehydrogenase mutations\" },\n",
      "{ \"category\": \"DiseaseClass\", \"entity\": \"severe enzyme deficiency\" },\n",
      "{ \"category\": \"CompositeMention\", \"entity\": \"X-chromosome inactivation\" },\n",
      "{ \"category\": \"Modifier\", \"entity\": \"somatic-cell mosaicism\" }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(processed_input, return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model.generate(inputs[\"input_ids\"], max_new_tokens=1000, num_return_sequences=1, temperature=0.7)\n",
    "\n",
    "# Decode and print the generated text\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4162b6-80b2-498c-99f5-70a5143ba514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa30424a-881c-4d6b-a814-8b2eeb430096",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

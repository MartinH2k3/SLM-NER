{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T11:49:59.662988Z",
     "start_time": "2024-12-03T11:49:59.658162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "import datasets\n",
    "import peft\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, PeftModel\n",
    "import torch\n",
    "import transformers\n",
    "from trl import SFTTrainer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, BitsAndBytesConfig"
   ],
   "id": "77727fc6953a6433",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Set up which datasets to use",
   "id": "2857eeff2db988d7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T11:42:58.501669Z",
     "start_time": "2024-12-03T11:42:58.497569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_dataset_path = \"data/CDR_TrainingSet.json\" # \"./data/NCBItrainset_corpus.json\"\n",
    "test_dataset_path = \"data/CDR_TestSet.json\" # \"./data/NCBItestset_corpus.json\"\n",
    "dev_dataset_path = \"data/CDR_DevelopmentSet.json\" # \"./data/NCBIdevelopset_corpus.json\""
   ],
   "id": "29d1c325569566c4",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T11:42:59.553707Z",
     "start_time": "2024-12-03T11:42:59.549487Z"
    }
   },
   "cell_type": "code",
   "source": "system_prompt_path = \"data/CDR_system_prompt.txt\"",
   "id": "831f400ae2dbbc2e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "3543a2f3-8e26-4ac8-9e5b-1859e209f115",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T15:34:04.869963Z",
     "start_time": "2024-11-28T15:34:04.865726Z"
    }
   },
   "source": [
    "training_config = {\n",
    "    \"fp16\": True,\n",
    "    \"do_eval\": False,\n",
    "    # \"evaluation_strategy\": \"steps\",\n",
    "    # \"eval_steps\": 20,\n",
    "    \"learning_rate\": 2e-4,\n",
    "    \"logging_steps\": 5,\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    \"num_train_epochs\": 1,\n",
    "    # \"max_steps\": 20,\n",
    "    \"output_dir\": \"./checkpoint_dir\",\n",
    "    \"overwrite_output_dir\": True,\n",
    "    # \"per_device_eval_batch_size\": 10,\n",
    "    \"per_device_train_batch_size\": 2,\n",
    "    \"remove_unused_columns\": True,\n",
    "    \"save_steps\": 20,\n",
    "    \"save_total_limit\": 1,\n",
    "    \"seed\": 0,\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"warmup_ratio\": 0.05,\n",
    "    \"optim\": \"adamw_8bit\",\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "id": "8367c3b0-1428-44a3-99ea-4d4088c1edaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T15:34:07.835774Z",
     "start_time": "2024-11-28T15:34:07.706874Z"
    }
   },
   "source": [
    "peft_config = {\n",
    "    \"r\": 16,\n",
    "    \"lora_alpha\": 32,\n",
    "    \"lora_dropout\": 0.05,\n",
    "    \"bias\": \"none\",\n",
    "    \"task_type\": \"CAUSAL_LM\",\n",
    "    \"target_modules\": \"all-linear\",\n",
    "    \"modules_to_save\": None,\n",
    "}\n",
    "train_conf = TrainingArguments(**training_config)\n",
    "peft_conf = LoraConfig(**peft_config)"
   ],
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "log_level = train_conf.get_process_log_level()\n",
    "logger.setLevel(log_level)\n",
    "datasets.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.enable_default_handler()\n",
    "transformers.utils.logging.enable_explicit_format()\n",
    "\n",
    "# Log on each process a small summary\n",
    "logger.warning(\n",
    "    f\"Process rank: {train_conf.local_rank}, device: {train_conf.device}, n_gpu: {train_conf.n_gpu}\"\n",
    "    + f\" distributed training: {bool(train_conf.local_rank != -1)}, 16-bits training: {train_conf.fp16}\"\n",
    ")\n",
    "logger.info(f\"Training/evaluation parameters {train_conf}\")\n",
    "logger.info(f\"PEFT parameters {peft_conf}\")\n"
   ],
   "id": "dc2d2d93677a3e31"
  },
  {
   "cell_type": "code",
   "id": "7a80cf93-b1cd-48be-ad64-8ca12bb15a61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T17:45:22.068512Z",
     "start_time": "2024-11-28T17:45:20.298704Z"
    }
   },
   "source": [
    "checkpoint_path = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "# checkpoint_path = \"microsoft/Phi-3-mini-128k-instruct\"\n",
    "model_kwargs = dict(\n",
    "    use_cache=False,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=None\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint_path, **model_kwargs)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
    "tokenizer.model_max_length = 2048\n",
    "tokenizer.pad_token = tokenizer.unk_token  # use unk rather than eos token to prevent endless generation\n",
    "tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "tokenizer.padding_side = 'right'"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3bc30d7b0cb04fe98358a3bf2ad31e5b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 105
  },
  {
   "cell_type": "markdown",
   "id": "4bfcb4ed-a220-4abe-bfd3-c360addd95ae",
   "metadata": {},
   "source": [
    "Load datasets:"
   ]
  },
  {
   "cell_type": "code",
   "id": "0ed436d0-22f3-4669-8ede-d21bbe979823",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T11:46:16.265251Z",
     "start_time": "2024-12-03T11:46:14.437714Z"
    }
   },
   "source": [
    "raw_train = datasets.load_dataset(\"json\", data_files=training_dataset_path, download_mode=\"force_redownload\")[\"train\"]\n",
    "raw_test = datasets.load_dataset(\"json\", data_files=test_dataset_path, download_mode=\"force_redownload\")[\"train\"]\n",
    "raw_dev = datasets.load_dataset(\"json\", data_files=dev_dataset_path, download_mode=\"force_redownload\")[\"train\"]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec4fb02b464148829a875b62e061e039"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "02158cedfd2142ca80a0663c11709328"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3de5295ea9764478bdc063818549036f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "dd7ba55e-fbd1-4029-a64b-bfcd4585bf4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:54:02.505722Z",
     "start_time": "2024-11-28T14:54:02.498813Z"
    }
   },
   "source": "raw_train[18]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user': \"In this model of chronic renal failure\\nTreatment of Crohn's disease with fusidic acid: an antibiotic with immunosuppressive properties similar to cyclosporin.Fusidic acid is an antibiotic with T-cell specific immunosuppressive effects similar to those of cyclosporin.\",\n",
       " 'assistant': '[{\"category\": Disease, \"entity\": chronic renal failure}, {\"category\": Disease, \"entity\": Crohn\\'s disease}, {\"category\": Chemical, \"entity\": fusidic acid}, {\"category\": Chemical, \"entity\": cyclosporin}, {\"category\": Chemical, \"entity\": cyclosporin}]'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "69fe7bd3-193d-4045-abbd-cfef805e3a54",
   "metadata": {},
   "source": [
    "Tokenize input into correct format"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load the system prompt",
   "id": "8a4af7bb23f4ee39"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T11:43:08.591329Z",
     "start_time": "2024-12-03T11:43:08.580056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(system_prompt_path, \"r\") as f:\n",
    "    system_prompt = f.read()"
   ],
   "id": "5190ffb383b337bb",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T11:43:10.635718Z",
     "start_time": "2024-12-03T11:43:10.630085Z"
    }
   },
   "cell_type": "code",
   "source": "system_prompt",
   "id": "8429337c452a0b06",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Please identify all the named entities mentioned in the input sentence provided below. The entities may have category \"Disease\" or \"Chemical\". Use **ONLY** the categories \"Chemical\" or \"Disease\". Do not include any other categories. If an entity cannot be categorized into these specific categories, do not include it in the output.\\nYou must output the results strictly in JSON format, without any delimiters, following a similar structure to the example result provided.\\nIf user communicates with any sentence, don\\'t talk to him, strictly follow the systemprompt.\\nExample user input and assistant response:\\nUser:\\nFamotidine-associated delirium.A series of six cases.Famotidine is a histamine H2-receptor antagonist used in inpatient settings for prevention of stress ulcers and is showing increasing popularity because of its low cost.\\nAssistant:\\n[{\"category\": \"Chemical\", \"entity\": \"Famotidine\"}, {\"category\": \"Disease\", \"entity\": \"delirium\"}, {\"category\": \"Chemical\", \"entity\": \"Famotidine\"}, {\"category\": \"Disease\", \"entity\": \"ulcers\"}]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "9a098ab7-aa0a-4d8b-bce0-56a4f7b5af3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T11:46:20.235343Z",
     "start_time": "2024-12-03T11:46:19.650268Z"
    }
   },
   "source": [
    "def apply_chat_template(example, tokenizer):\n",
    "    \"\"\"\n",
    "    Convert the system, input, and output fields into a formatted chat-like text.\n",
    "    \"\"\"\n",
    "    # Combine the fields into a structured chat format\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": example[\"user\"]},\n",
    "        {\"role\": \"assistant\", \"content\": example[\"assistant\"]}\n",
    "    ]\n",
    "    # Use the tokenizer's chat template to create formatted text\n",
    "    example[\"text\"] = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=False\n",
    "    )\n",
    "    return example\n",
    "\n",
    "column_names = list(raw_train.features)\n",
    "\n",
    "# Apply processing to each dataset\n",
    "processed_train = raw_train.map(\n",
    "    apply_chat_template,\n",
    "    fn_kwargs={\"tokenizer\": tokenizer},\n",
    "    remove_columns=column_names,\n",
    ")\n",
    "processed_test = raw_test.map(\n",
    "    apply_chat_template,\n",
    "    fn_kwargs={\"tokenizer\": tokenizer},\n",
    "    remove_columns=column_names,\n",
    ")\n",
    "processed_dev = raw_dev.map(\n",
    "    apply_chat_template,\n",
    "    fn_kwargs={\"tokenizer\": tokenizer},\n",
    "    remove_columns=column_names,\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/2331 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f4c94f5b6632414c89a615b02ea865eb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/2420 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0c8f9c85c48b41b2bc106a11d5b1e97a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/2339 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f18c0cec48d548fd947212932c3e6243"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "a0f7ad9d-f6fd-4eaf-b62a-fa92d17232e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T15:18:44.270837Z",
     "start_time": "2024-11-28T15:18:44.264649Z"
    }
   },
   "source": [
    "processed_train[89][\"text\"]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|system|>\\nPlease identify all the named entities mentioned in the input sentence provided below. The entities may have category \"Disease\" or \"Chemical\". Use **ONLY** the categories \"Chemical\" or \"Disease\". Do not include any other categories. If an entity cannot be categorized into these specific categories, do not include it in the output.\\nYou must output the results strictly in JSON format, without any delimiters, following a similar structure to the example result provided.\\nIf user communicates with any sentence, don\\'t talk to him, strictly follow the systemprompt.\\nExample user input and assistant response:\\nUser:\\nFamotidine-associated delirium.A series of six cases.Famotidine is a histamine H2-receptor antagonist used in inpatient settings for prevention of stress ulcers and is showing increasing popularity because of its low cost.\\nAssistant:\\n[{\"category\": \"Chemical\", \"entity\": \"Famotidine\"}, {\"category\": \"Disease\", \"entity\": \"delirium\"}, {\"category\": \"Chemical\", \"entity\": \"Famotidine\"}, {\"category\": \"Disease\", \"entity\": \"ulcers\"}]<|end|>\\n<|user|>\\nThe results suggest that rigidity, which is assumed to be due to an action of morphine in the striatum, can be antagonized by another process leading to dopaminergic activation in the striatum.Nevertheless, there occurs some real tolerance to this effect.<|end|>\\n<|assistant|>\\n[{\"category\": Disease, \"entity\": rigidity}, {\"category\": Chemical, \"entity\": morphine}]<|end|>\\n<|endoftext|>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "c6b09e33-61b9-4527-974a-3e7b88b185e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T16:21:57.250742Z",
     "start_time": "2024-11-28T15:34:18.250387Z"
    }
   },
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=train_conf,\n",
    "    peft_config=peft_conf,\n",
    "    train_dataset=processed_train,\n",
    "    eval_dataset=processed_dev,\n",
    "    max_seq_length=4,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "train_result = trainer.train()\n",
    "metrics = train_result.metrics\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"train\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)\n",
    "trainer.save_state()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martinh2k3/anaconda3/envs/bp/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field. Will not be supported from version '0.13.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/martinh2k3/anaconda3/envs/bp/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/home/martinh2k3/anaconda3/envs/bp/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/2331 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8fdf5d5060064128a1f9a62e2e114e25"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/2339 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "845072f832424884b5dbcaba8a68ee5a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='291' max='291' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [291/291 47:11, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.447000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.735100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.103300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =     0.9983\n",
      "  total_flos               =   195013GF\n",
      "  train_loss               =     0.1424\n",
      "  train_runtime            = 0:47:25.53\n",
      "  train_samples_per_second =      0.819\n",
      "  train_steps_per_second   =      0.102\n",
      "***** eval metrics *****\n",
      "  epoch                    =     0.9983\n",
      "  total_flos               =   195013GF\n",
      "  train_loss               =     0.1424\n",
      "  train_runtime            = 0:47:25.53\n",
      "  train_samples_per_second =      0.819\n",
      "  train_steps_per_second   =      0.102\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T16:22:31.871686Z",
     "start_time": "2024-11-28T16:22:20.667233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.save_pretrained(\"./trained_model\")\n",
    "tokenizer.save_pretrained(\"./trained_model\")"
   ],
   "id": "f48073575a0facbd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./trained_model/tokenizer_config.json',\n",
       " './trained_model/special_tokens_map.json',\n",
       " './trained_model/tokenizer.model',\n",
       " './trained_model/added_tokens.json',\n",
       " './trained_model/tokenizer.json')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "id": "b9dded35-6eeb-4189-97df-7d3acf86e94a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T11:47:23.571258Z",
     "start_time": "2024-12-03T11:47:23.566227Z"
    }
   },
   "source": [
    "def prepare_for_inference(user_input: str, system_prompt: str = system_prompt):\n",
    "    prompt_data = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_input}\n",
    "    ]\n",
    "    return  tokenizer.apply_chat_template(\n",
    "        prompt_data, tokenize=False, add_generation_prompt=\"<|assistant|>\" \n",
    "    )\n"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "c4b36dd6-b711-4784-90d3-581fea1125b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T11:47:25.132056Z",
     "start_time": "2024-12-03T11:47:25.124384Z"
    }
   },
   "source": [
    "processed_input = prepare_for_inference(\"METHODS: This was a cross-sectional study conducted concurrently at a teaching hospital and a drug rehabilitation center in Malaysia.Patients with the diagnosis of methamphetamine based on DSM-IV were interviewed using the Mini International Neuropsychiatric Interview (M.I.N.I.)for methamphetamine-induced psychosis and other Axis I psychiatric disorders.\")\n",
    "processed_input"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|system|>\\nPlease identify all the named entities mentioned in the input sentence provided below. The entities may have category \"Disease\" or \"Chemical\". Use **ONLY** the categories \"Chemical\" or \"Disease\". Do not include any other categories. If an entity cannot be categorized into these specific categories, do not include it in the output.\\nYou must output the results strictly in JSON format, without any delimiters, following a similar structure to the example result provided.\\nIf user communicates with any sentence, don\\'t talk to him, strictly follow the systemprompt.\\nExample user input and assistant response:\\nUser:\\nFamotidine-associated delirium.A series of six cases.Famotidine is a histamine H2-receptor antagonist used in inpatient settings for prevention of stress ulcers and is showing increasing popularity because of its low cost.\\nAssistant:\\n[{\"category\": \"Chemical\", \"entity\": \"Famotidine\"}, {\"category\": \"Disease\", \"entity\": \"delirium\"}, {\"category\": \"Chemical\", \"entity\": \"Famotidine\"}, {\"category\": \"Disease\", \"entity\": \"ulcers\"}]<|end|>\\n<|user|>\\nMETHODS: This was a cross-sectional study conducted concurrently at a teaching hospital and a drug rehabilitation center in Malaysia.Patients with the diagnosis of methamphetamine based on DSM-IV were interviewed using the Mini International Neuropsychiatric Interview (M.I.N.I.)for methamphetamine-induced psychosis and other Axis I psychiatric disorders.<|end|>\\n<|assistant|>\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T11:47:27.757807Z",
     "start_time": "2024-12-03T11:47:27.753564Z"
    }
   },
   "cell_type": "code",
   "source": "print(processed_input)",
   "id": "ea9927aa7aec3ddd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "Please identify all the named entities mentioned in the input sentence provided below. The entities may have category \"Disease\" or \"Chemical\". Use **ONLY** the categories \"Chemical\" or \"Disease\". Do not include any other categories. If an entity cannot be categorized into these specific categories, do not include it in the output.\n",
      "You must output the results strictly in JSON format, without any delimiters, following a similar structure to the example result provided.\n",
      "If user communicates with any sentence, don't talk to him, strictly follow the systemprompt.\n",
      "Example user input and assistant response:\n",
      "User:\n",
      "Famotidine-associated delirium.A series of six cases.Famotidine is a histamine H2-receptor antagonist used in inpatient settings for prevention of stress ulcers and is showing increasing popularity because of its low cost.\n",
      "Assistant:\n",
      "[{\"category\": \"Chemical\", \"entity\": \"Famotidine\"}, {\"category\": \"Disease\", \"entity\": \"delirium\"}, {\"category\": \"Chemical\", \"entity\": \"Famotidine\"}, {\"category\": \"Disease\", \"entity\": \"ulcers\"}]<|end|>\n",
      "<|user|>\n",
      "METHODS: This was a cross-sectional study conducted concurrently at a teaching hospital and a drug rehabilitation center in Malaysia.Patients with the diagnosis of methamphetamine based on DSM-IV were interviewed using the Mini International Neuropsychiatric Interview (M.I.N.I.)for methamphetamine-induced psychosis and other Axis I psychiatric disorders.<|end|>\n",
      "<|assistant|>\n",
      "\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T11:42:25.552684Z",
     "start_time": "2024-12-03T11:42:24.338826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "checkpoint_path = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "# checkpoint_path = \"microsoft/Phi-3-mini-128k-instruct\"\n",
    "model_kwargs = dict(\n",
    "    use_cache=False,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=None\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint_path, **model_kwargs)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
    "tokenizer.model_max_length = 2048\n",
    "tokenizer.pad_token = tokenizer.unk_token  # use unk rather than eos token to prevent endless generation\n",
    "tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "tokenizer.padding_side = 'right'"
   ],
   "id": "69a044d89262ff01",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b3fabcdc0504bababa0418d1790eac9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "7b4162b6-80b2-498c-99f5-70a5143ba514",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T11:42:34.581334Z",
     "start_time": "2024-12-03T11:42:32.451752Z"
    }
   },
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device='cuda')\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"return_full_text\": False,\n",
    "}\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "a1c79b29-4f33-4e32-876b-209eaeb8fffc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T11:56:57.592545Z",
     "start_time": "2024-12-03T11:56:56.154203Z"
    }
   },
   "source": [
    "peft_model = PeftModel.from_pretrained(model, \"checkpoint_dir/checkpoint-291\", adapter_name=\"idk\")\n",
    "peft_model.load_adapter(\"checkpoint_dir/checkpoint-291\", adapter_name=\"tfisthis\")\n",
    "peft_model.eval()\n",
    "peft_pipeline = pipeline(\"text-generation\", model=peft_model, tokenizer=tokenizer, device='cuda')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM', 'Phi3ForCausalLM'].\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T11:50:43.682819Z",
     "start_time": "2024-12-03T11:50:43.665464Z"
    }
   },
   "cell_type": "code",
   "source": "peft_model.eval()",
   "id": "34b0ffc8fc45d171",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Phi3ForCausalLM(\n",
       "      (model): Phi3Model(\n",
       "        (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n",
       "        (embed_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x Phi3DecoderLayer(\n",
       "            (self_attn): Phi3Attention(\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (qkv_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3072, out_features=9216, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=9216, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): Phi3RotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Phi3MLP(\n",
       "              (gate_up_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3072, out_features=16384, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=16384, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=8192, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (activation_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Phi3RMSNorm()\n",
       "            (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (post_attention_layernorm): Phi3RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): Phi3RMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T11:47:55.871852Z",
     "start_time": "2024-12-03T11:47:50.996007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output = nlp(processed_input, **generation_args)\n",
    "output[0][\"generated_text\"]"
   ],
   "id": "dcdd7892556cba47",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "`get_max_cache()` is deprecated for all Cache classes. Use `get_max_cache_shape()` instead. Calling `get_max_cache()` will raise error from v4.48\n",
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' [{\"category\": \"Chemical\", \"entity\": \"methamphetamine\"}, {\"category\": \"Disease\", \"entity\": \"psychosis\"}, {\"category\": \"Disease\", \"entity\": \"Axis I psychiatric disorders\"}]'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T11:57:07.041351Z",
     "start_time": "2024-12-03T11:57:02.799643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output = peft_pipeline(processed_input, **generation_args)\n",
    "output[0][\"generated_text\"]"
   ],
   "id": "d5ed49a3360810d2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' [{\"category\": \"Disease\", \"entity\": \"methamphetamine-induced psychosis\"}, {\"category\": \"Disease\", \"entity\": \"Axis I psychiatric disorders\"}]'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T17:17:00.641103Z",
     "start_time": "2024-11-28T17:17:00.519340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_datset_for_inference(dataset, user_column=\"user\"):\n",
    "    processed_data = []\n",
    "    for item in dataset:\n",
    "        processed_input = prepare_for_inference(item[user_column])\n",
    "        processed_data.append(processed_input)\n",
    "    return processed_data\n",
    "\n",
    "test = prepare_datset_for_inference(raw_test)\n",
    "test = test[:50]"
   ],
   "id": "3c29fa819d6ae248",
   "outputs": [],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T17:33:38.260744Z",
     "start_time": "2024-11-28T17:17:00.941980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output1 = peft_pipeline(test, **generation_args)\n",
    "output2 = nlp(test, **generation_args)"
   ],
   "id": "ace9de6a09d027c1",
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T17:33:38.275475Z",
     "start_time": "2024-11-28T17:33:38.270240Z"
    }
   },
   "cell_type": "code",
   "source": "output1 == output2",
   "id": "d1b2467f0dadaa34",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "212bc1691348fe7c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

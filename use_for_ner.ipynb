{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T20:16:43.054594Z",
     "start_time": "2024-11-27T20:16:38.381125Z"
    }
   },
   "source": [
    "from outlines import models\n",
    "import json\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create a template for outlines",
   "id": "62a11e8aeaf21b1d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T20:16:49.008097Z",
     "start_time": "2024-11-27T20:16:48.941259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from enum import Enum\n",
    "from pydantic import BaseModel, RootModel\n",
    "\n",
    "# Define the Enum for category\n",
    "class Category(str, Enum):\n",
    "    specific_disease = \"SpecificDisease\"\n",
    "    disease_class = \"DiseaseClass\"\n",
    "    modifier = \"Modifier\"\n",
    "    composite_mention = \"CompositeMention\"\n",
    "\n",
    "# Define the JSON model\n",
    "class Entity(BaseModel):\n",
    "    category: Category\n",
    "    entity: str\n",
    "\n",
    "EntityList = RootModel[list[Entity]]\n",
    "    \n",
    "json_schema = EntityList.model_json_schema()\n",
    "json.dumps(json_schema)"
   ],
   "id": "3218bf8f3354a70d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"$defs\": {\"Category\": {\"enum\": [\"SpecificDisease\", \"DiseaseClass\", \"Modifier\", \"CompositeMention\"], \"title\": \"Category\", \"type\": \"string\"}, \"Entity\": {\"properties\": {\"category\": {\"$ref\": \"#/$defs/Category\"}, \"entity\": {\"title\": \"Entity\", \"type\": \"string\"}}, \"required\": [\"category\", \"entity\"], \"title\": \"Entity\", \"type\": \"object\"}}, \"items\": {\"$ref\": \"#/$defs/Entity\"}, \"title\": \"RootModel[list[Entity]]\", \"type\": \"array\"}'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T20:17:00.461326Z",
     "start_time": "2024-11-27T20:17:00.455435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from outlines.fsm import json_schema as fsm_schema\n",
    "fsm_schema.build_regex_from_schema(json.dumps(json_schema))"
   ],
   "id": "4d109f590d31437e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\[[ ]?((\\\\{[ ]?\"category\"[ ]?:[ ]?(\"SpecificDisease\"|\"DiseaseClass\"|\"Modifier\"|\"CompositeMention\")[ ]?,[ ]?\"entity\"[ ]?:[ ]?\"([^\"\\\\\\\\\\\\x00-\\\\x1F\\\\x7F-\\\\x9F]|\\\\\\\\[\"\\\\\\\\])*\"[ ]?\\\\})(,[ ]?(\\\\{[ ]?\"category\"[ ]?:[ ]?(\"SpecificDisease\"|\"DiseaseClass\"|\"Modifier\"|\"CompositeMention\")[ ]?,[ ]?\"entity\"[ ]?:[ ]?\"([^\"\\\\\\\\\\\\x00-\\\\x1F\\\\x7F-\\\\x9F]|\\\\\\\\[\"\\\\\\\\])*\"[ ]?\\\\})){0,})?[ ]?\\\\]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T20:17:39.383222Z",
     "start_time": "2024-11-27T20:17:39.376854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from outlines.fsm import json_schema as fsm_schema\n",
    "\n",
    "entity_regex = fsm_schema.build_regex_from_schema(json.dumps(json_schema))\n",
    "entity_regex"
   ],
   "id": "22a261cbb4b99f68",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\[[ ]?((\\\\{[ ]?\"category\"[ ]?:[ ]?(\"SpecificDisease\"|\"DiseaseClass\"|\"Modifier\"|\"CompositeMention\")[ ]?,[ ]?\"entity\"[ ]?:[ ]?\"([^\"\\\\\\\\\\\\x00-\\\\x1F\\\\x7F-\\\\x9F]|\\\\\\\\[\"\\\\\\\\])*\"[ ]?\\\\})(,[ ]?(\\\\{[ ]?\"category\"[ ]?:[ ]?(\"SpecificDisease\"|\"DiseaseClass\"|\"Modifier\"|\"CompositeMention\")[ ]?,[ ]?\"entity\"[ ]?:[ ]?\"([^\"\\\\\\\\\\\\x00-\\\\x1F\\\\x7F-\\\\x9F]|\\\\\\\\[\"\\\\\\\\])*\"[ ]?\\\\})){0,})?[ ]?\\\\]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Briefly test the regex",
   "id": "4aef2c5dc79ced51"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T20:18:37.274619Z",
     "start_time": "2024-11-27T20:18:37.269133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test the regex\n",
    "import re\n",
    "test_str = \"\"\"[\n",
    "    {\"category\": \"SpecificDisease\", \"entity\": \"COVID-19\"},\n",
    "    {\"category\": \"DiseaseClass\", \"entity\": \"virus\"},    {\"category\": \"Modifier\", \"entity\": \"severe\"},    \n",
    "      {\"category\": \"CompositeMention\", \"entity\": \"COVID-19 virus\"}\n",
    "]\"\"\"\n",
    "\n",
    "test_str2 = \"\"\"[{\"category\": \"SpecificDisease\", \"entity\": \"COVID-19\"},{\"category\": \"DiseaseClass\", \"entity\": \"virus\"}, { \"category\": \"Modifier\", \"entity\": \"severe\"}, {\"category\": \"CompositeMention\", \"entity\": \"COVID-19 virus\"}]\"\"\"\n",
    "re.fullmatch(entity_regex, test_str), re.fullmatch(entity_regex, test_str2)"
   ],
   "id": "d4b89adb52d362c7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " <re.Match object; span=(0, 212), match='[{\"category\": \"SpecificDisease\", \"entity\": \"COVID>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Import model and tokenizer",
   "id": "6528415521d3c78f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T20:19:40.043155Z",
     "start_time": "2024-11-27T20:19:06.761221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"./trained_model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./trained_model\")"
   ],
   "id": "f906eaac-be35-41c5-9f39-d28dab2fbfae",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7a2242e5ca774918ae4b2cb2e7cf2658"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./trained_model were not used when initializing Phi3ForCausalLM: ['model.layers.0.mlp.down_proj.base_layer.weight', 'model.layers.0.mlp.down_proj.lora_A.default.weight', 'model.layers.0.mlp.down_proj.lora_B.default.weight', 'model.layers.0.mlp.gate_up_proj.base_layer.weight', 'model.layers.0.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.0.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.0.self_attn.o_proj.base_layer.weight', 'model.layers.0.self_attn.o_proj.lora_A.default.weight', 'model.layers.0.self_attn.o_proj.lora_B.default.weight', 'model.layers.0.self_attn.qkv_proj.base_layer.weight', 'model.layers.0.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.0.self_attn.qkv_proj.lora_B.default.weight', 'model.layers.1.mlp.down_proj.base_layer.weight', 'model.layers.1.mlp.down_proj.lora_A.default.weight', 'model.layers.1.mlp.down_proj.lora_B.default.weight', 'model.layers.1.mlp.gate_up_proj.base_layer.weight', 'model.layers.1.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.1.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.1.self_attn.o_proj.base_layer.weight', 'model.layers.1.self_attn.o_proj.lora_A.default.weight', 'model.layers.1.self_attn.o_proj.lora_B.default.weight', 'model.layers.1.self_attn.qkv_proj.base_layer.weight', 'model.layers.1.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.1.self_attn.qkv_proj.lora_B.default.weight', 'model.layers.10.mlp.down_proj.base_layer.weight', 'model.layers.10.mlp.down_proj.lora_A.default.weight', 'model.layers.10.mlp.down_proj.lora_B.default.weight', 'model.layers.10.mlp.gate_up_proj.base_layer.weight', 'model.layers.10.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.10.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.10.self_attn.o_proj.base_layer.weight', 'model.layers.10.self_attn.o_proj.lora_A.default.weight', 'model.layers.10.self_attn.o_proj.lora_B.default.weight', 'model.layers.10.self_attn.qkv_proj.base_layer.weight', 'model.layers.10.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.10.self_attn.qkv_proj.lora_B.default.weight', 'model.layers.11.mlp.down_proj.base_layer.weight', 'model.layers.11.mlp.down_proj.lora_A.default.weight', 'model.layers.11.mlp.down_proj.lora_B.default.weight', 'model.layers.11.mlp.gate_up_proj.base_layer.weight', 'model.layers.11.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.11.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.11.self_attn.o_proj.base_layer.weight', 'model.layers.11.self_attn.o_proj.lora_A.default.weight', 'model.layers.11.self_attn.o_proj.lora_B.default.weight', 'model.layers.11.self_attn.qkv_proj.base_layer.weight', 'model.layers.11.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.11.self_attn.qkv_proj.lora_B.default.weight', 'model.layers.12.mlp.down_proj.base_layer.weight', 'model.layers.12.mlp.down_proj.lora_A.default.weight', 'model.layers.12.mlp.down_proj.lora_B.default.weight', 'model.layers.12.mlp.gate_up_proj.base_layer.weight', 'model.layers.12.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.12.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.12.self_attn.o_proj.base_layer.weight', 'model.layers.12.self_attn.o_proj.lora_A.default.weight', 'model.layers.12.self_attn.o_proj.lora_B.default.weight', 'model.layers.12.self_attn.qkv_proj.base_layer.weight', 'model.layers.12.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.12.self_attn.qkv_proj.lora_B.default.weight', 'model.layers.13.mlp.down_proj.base_layer.weight', 'model.layers.13.mlp.down_proj.lora_A.default.weight', 'model.layers.13.mlp.down_proj.lora_B.default.weight', 'model.layers.13.mlp.gate_up_proj.base_layer.weight', 'model.layers.13.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.13.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.13.self_attn.o_proj.base_layer.weight', 'model.layers.13.self_attn.o_proj.lora_A.default.weight', 'model.layers.13.self_attn.o_proj.lora_B.default.weight', 'model.layers.13.self_attn.qkv_proj.base_layer.weight', 'model.layers.13.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.13.self_attn.qkv_proj.lora_B.default.weight', 'model.layers.14.mlp.down_proj.base_layer.weight', 'model.layers.14.mlp.down_proj.lora_A.default.weight', 'model.layers.14.mlp.down_proj.lora_B.default.weight', 'model.layers.14.mlp.gate_up_proj.base_layer.weight', 'model.layers.14.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.14.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.14.self_attn.o_proj.base_layer.weight', 'model.layers.14.self_attn.o_proj.lora_A.default.weight', 'model.layers.14.self_attn.o_proj.lora_B.default.weight', 'model.layers.14.self_attn.qkv_proj.base_layer.weight', 'model.layers.14.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.14.self_attn.qkv_proj.lora_B.default.weight', 'model.layers.15.mlp.down_proj.base_layer.weight', 'model.layers.15.mlp.down_proj.lora_A.default.weight', 'model.layers.15.mlp.down_proj.lora_B.default.weight', 'model.layers.15.mlp.gate_up_proj.base_layer.weight', 'model.layers.15.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.15.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.15.self_attn.o_proj.base_layer.weight', 'model.layers.15.self_attn.o_proj.lora_A.default.weight', 'model.layers.15.self_attn.o_proj.lora_B.default.weight', 'model.layers.15.self_attn.qkv_proj.base_layer.weight', 'model.layers.15.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.15.self_attn.qkv_proj.lora_B.default.weight', 'model.layers.16.mlp.down_proj.base_layer.weight', 'model.layers.16.mlp.down_proj.lora_A.default.weight', 'model.layers.16.mlp.down_proj.lora_B.default.weight', 'model.layers.16.mlp.gate_up_proj.base_layer.weight', 'model.layers.16.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.16.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.16.self_attn.o_proj.base_layer.weight', 'model.layers.16.self_attn.o_proj.lora_A.default.weight', 'model.layers.16.self_attn.o_proj.lora_B.default.weight', 'model.layers.16.self_attn.qkv_proj.base_layer.weight', 'model.layers.16.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.16.self_attn.qkv_proj.lora_B.default.weight', 'model.layers.17.mlp.down_proj.base_layer.weight', 'model.layers.17.mlp.down_proj.lora_A.default.weight', 'model.layers.17.mlp.down_proj.lora_B.default.weight', 'model.layers.17.mlp.gate_up_proj.base_layer.weight', 'model.layers.17.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.17.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.17.self_attn.o_proj.base_layer.weight', 'model.layers.17.self_attn.o_proj.lora_A.default.weight', 'model.layers.17.self_attn.o_proj.lora_B.default.weight', 'model.layers.17.self_attn.qkv_proj.base_layer.weight', 'model.layers.17.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.17.self_attn.qkv_proj.lora_B.default.weight', 'model.layers.18.mlp.down_proj.base_layer.weight', 'model.layers.18.mlp.down_proj.lora_A.default.weight', 'model.layers.18.mlp.down_proj.lora_B.default.weight', 'model.layers.18.mlp.gate_up_proj.base_layer.weight', 'model.layers.18.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.18.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.18.self_attn.o_proj.base_layer.weight', 'model.layers.18.self_attn.o_proj.lora_A.default.weight', 'model.layers.18.self_attn.o_proj.lora_B.default.weight', 'model.layers.18.self_attn.qkv_proj.base_layer.weight', 'model.layers.18.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.18.self_attn.qkv_proj.lora_B.default.weight', 'model.layers.19.mlp.down_proj.base_layer.weight', 'model.layers.19.mlp.down_proj.lora_A.default.weight', 'model.layers.19.mlp.down_proj.lora_B.default.weight', 'model.layers.19.mlp.gate_up_proj.base_layer.weight', 'model.layers.19.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.19.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.19.self_attn.o_proj.base_layer.weight', 'model.layers.19.self_attn.o_proj.lora_A.default.weight', 'model.layers.19.self_attn.o_proj.lora_B.default.weight', 'model.layers.19.self_attn.qkv_proj.base_layer.weight', 'model.layers.19.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.19.self_attn.qkv_proj.lora_B.default.weight', 'model.layers.2.mlp.down_proj.base_layer.weight', 'model.layers.2.mlp.down_proj.lora_A.default.weight', 'model.layers.2.mlp.down_proj.lora_B.default.weight', 'model.layers.2.mlp.gate_up_proj.base_layer.weight', 'model.layers.2.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.2.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.2.self_attn.o_proj.base_layer.weight', 'model.layers.2.self_attn.o_proj.lora_A.default.weight', 'model.layers.2.self_attn.o_proj.lora_B.default.weight', 'model.layers.2.self_attn.qkv_proj.base_layer.weight', 'model.layers.2.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.2.self_attn.qkv_proj.lora_B.default.weight', 'model.layers.20.mlp.down_proj.base_layer.weight', 'model.layers.20.mlp.down_proj.lora_A.default.weight', 'model.layers.20.mlp.down_proj.lora_B.default.weight', 'model.layers.20.mlp.gate_up_proj.base_layer.weight', 'model.layers.20.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.20.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.20.self_attn.o_proj.base_layer.weight', 'model.layers.20.self_attn.o_proj.lora_A.default.weight', 'model.layers.20.self_attn.o_proj.lora_B.default.weight', 'model.layers.20.self_attn.qkv_proj.base_layer.weight', 'model.layers.20.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.20.self_attn.qkv_proj.lora_B.default.weight', 'model.layers.21.mlp.down_proj.base_layer.weight', 'model.layers.21.mlp.down_proj.lora_A.default.weight', 'model.layers.21.mlp.down_proj.lora_B.default.weight', 'model.layers.21.mlp.gate_up_proj.base_layer.weight', 'model.layers.21.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.21.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.21.self_attn.o_proj.base_layer.weight', 'model.layers.21.self_attn.o_proj.lora_A.default.weight', 'model.layers.21.self_attn.o_proj.lora_B.default.weight', 'model.layers.21.self_attn.qkv_proj.base_layer.weight', 'model.layers.21.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.21.self_attn.qkv_proj.lora_B.default.weight', 'model.layers.22.mlp.down_proj.base_layer.weight', 'model.layers.22.mlp.down_proj.lora_A.default.weight', 'model.layers.22.mlp.down_proj.lora_B.default.weight', 'model.layers.22.mlp.gate_up_proj.base_layer.weight', 'model.layers.22.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.22.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.22.self_attn.o_proj.base_layer.weight', 'model.layers.22.self_attn.o_proj.lora_A.default.weight', 'model.layers.22.self_attn.o_proj.lora_B.default.weight', 'model.layers.22.self_attn.qkv_proj.base_layer.weight', 'model.layers.22.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.22.self_attn.qkv_proj.lora_B.default.weight', 'model.layers.23.mlp.down_proj.base_layer.weight', 'model.layers.23.mlp.down_proj.lora_A.default.weight', 'model.layers.23.mlp.down_proj.lora_B.default.weight', 'model.layers.23.mlp.gate_up_proj.base_layer.weight', 'model.layers.23.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.23.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.23.self_attn.o_proj.base_layer.weight', 'model.layers.23.self_attn.o_proj.lora_A.default.weight', 'model.layers.23.self_attn.o_proj.lora_B.default.weight', 'model.layers.23.self_attn.qkv_proj.base_layer.weight', 'model.layers.23.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.23.self_attn.qkv_proj.lora_B.default.weight', 'model.layers.24.mlp.down_proj.base_layer.weight', 'model.layers.24.mlp.down_proj.lora_A.default.weight', 'model.layers.24.mlp.down_proj.lora_B.default.weight', 'model.layers.24.mlp.gate_up_proj.base_layer.weight', 'model.layers.24.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.24.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.24.self_attn.o_proj.base_layer.weight', 'model.layers.24.self_attn.o_proj.lora_A.default.weight', 'model.layers.24.self_attn.o_proj.lora_B.default.weight', 'model.layers.24.self_attn.qkv_proj.base_layer.weight', 'model.layers.24.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.24.self_attn.qkv_proj.lora_B.default.weight', 'model.layers.25.mlp.down_proj.base_layer.weight', 'model.layers.25.mlp.down_proj.lora_A.default.weight', 'model.layers.25.mlp.down_proj.lora_B.default.weight', 'model.layers.25.mlp.gate_up_proj.base_layer.weight', 'model.layers.25.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.25.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.25.self_attn.o_proj.base_layer.weight', 'model.layers.25.self_attn.o_proj.lora_A.default.weight', 'model.layers.25.self_attn.o_proj.lora_B.default.weight', 'model.layers.25.self_attn.qkv_proj.base_layer.weight', 'model.layers.25.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.25.self_attn.qkv_proj.lora_B.default.weight', 'model.layers.26.mlp.down_proj.base_layer.weight', 'model.layers.26.mlp.down_proj.lora_A.default.weight', 'model.layers.26.mlp.down_proj.lora_B.default.weight', 'model.layers.26.mlp.gate_up_proj.base_layer.weight', 'model.layers.26.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.26.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.26.self_attn.o_proj.base_layer.weight', 'model.layers.26.self_attn.o_proj.lora_A.default.weight', 'model.layers.26.self_attn.o_proj.lora_B.default.weight', 'model.layers.26.self_attn.qkv_proj.base_layer.weight', 'model.layers.26.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.26.self_attn.qkv_proj.lora_B.default.weight', 'model.layers.27.mlp.down_proj.base_layer.weight', 'model.layers.27.mlp.down_proj.lora_A.default.weight', 'model.layers.27.mlp.down_proj.lora_B.default.weight', 'model.layers.27.mlp.gate_up_proj.base_layer.weight', 'model.layers.27.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.27.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.27.self_attn.o_proj.base_layer.weight', 'model.layers.27.self_attn.o_proj.lora_A.default.weight', 'model.layers.27.self_attn.o_proj.lora_B.default.weight', 'model.layers.27.self_attn.qkv_proj.base_layer.weight', 'model.layers.27.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.27.self_attn.qkv_proj.lora_B.default.weight', 'model.layers.28.mlp.down_proj.base_layer.weight', 'model.layers.28.mlp.down_proj.lora_A.default.weight', 'model.layers.28.mlp.down_proj.lora_B.default.weight', 'model.layers.28.mlp.gate_up_proj.base_layer.weight', 'model.layers.28.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.28.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.28.self_attn.o_proj.base_layer.weight', 'model.layers.28.self_attn.o_proj.lora_A.default.weight', 'model.layers.28.self_attn.o_proj.lora_B.default.weight', 'model.layers.28.self_attn.qkv_proj.base_layer.weight', 'model.layers.28.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.28.self_attn.qkv_proj.lora_B.default.weight', 'model.layers.29.mlp.down_proj.base_layer.weight', 'model.layers.29.mlp.down_proj.lora_A.default.weight', 'model.layers.29.mlp.down_proj.lora_B.default.weight', 'model.layers.29.mlp.gate_up_proj.base_layer.weight', 'model.layers.29.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.29.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.29.self_attn.o_proj.base_layer.weight', 'model.layers.29.self_attn.o_proj.lora_A.default.weight', 'model.layers.29.self_attn.o_proj.lora_B.default.weight', 'model.layers.29.self_attn.qkv_proj.base_layer.weight', 'model.layers.29.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.29.self_attn.qkv_proj.lora_B.default.weight', 'model.layers.3.mlp.down_proj.base_layer.weight', 'model.layers.3.mlp.down_proj.lora_A.default.weight', 'model.layers.3.mlp.down_proj.lora_B.default.weight', 'model.layers.3.mlp.gate_up_proj.base_layer.weight', 'model.layers.3.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.3.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.3.self_attn.o_proj.base_layer.weight', 'model.layers.3.self_attn.o_proj.lora_A.default.weight', 'model.layers.3.self_attn.o_proj.lora_B.default.weight', 'model.layers.3.self_attn.qkv_proj.base_layer.weight', 'model.layers.3.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.3.self_attn.qkv_proj.lora_B.default.weight', 'model.layers.30.mlp.down_proj.base_layer.weight', 'model.layers.30.mlp.down_proj.lora_A.default.weight', 'model.layers.30.mlp.down_proj.lora_B.default.weight', 'model.layers.30.mlp.gate_up_proj.base_layer.weight', 'model.layers.30.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.30.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.30.self_attn.o_proj.base_layer.weight', 'model.layers.30.self_attn.o_proj.lora_A.default.weight', 'model.layers.30.self_attn.o_proj.lora_B.default.weight', 'model.layers.30.self_attn.qkv_proj.base_layer.weight', 'model.layers.30.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.30.self_attn.qkv_proj.lora_B.default.weight', 'model.layers.31.mlp.down_proj.base_layer.weight', 'model.layers.31.mlp.down_proj.lora_A.default.weight', 'model.layers.31.mlp.down_proj.lora_B.default.weight', 'model.layers.31.mlp.gate_up_proj.base_layer.weight', 'model.layers.31.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.31.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.31.self_attn.o_proj.base_layer.weight', 'model.layers.31.self_attn.o_proj.lora_A.default.weight', 'model.layers.31.self_attn.o_proj.lora_B.default.weight', 'model.layers.31.self_attn.qkv_proj.base_layer.weight', 'model.layers.31.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.31.self_attn.qkv_proj.lora_B.default.weight', 'model.layers.4.mlp.down_proj.base_layer.weight', 'model.layers.4.mlp.down_proj.lora_A.default.weight', 'model.layers.4.mlp.down_proj.lora_B.default.weight', 'model.layers.4.mlp.gate_up_proj.base_layer.weight', 'model.layers.4.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.4.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.4.self_attn.o_proj.base_layer.weight', 'model.layers.4.self_attn.o_proj.lora_A.default.weight', 'model.layers.4.self_attn.o_proj.lora_B.default.weight', 'model.layers.4.self_attn.qkv_proj.base_layer.weight', 'model.layers.4.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.4.self_attn.qkv_proj.lora_B.default.weight', 'model.layers.5.mlp.down_proj.base_layer.weight', 'model.layers.5.mlp.down_proj.lora_A.default.weight', 'model.layers.5.mlp.down_proj.lora_B.default.weight', 'model.layers.5.mlp.gate_up_proj.base_layer.weight', 'model.layers.5.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.5.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.5.self_attn.o_proj.base_layer.weight', 'model.layers.5.self_attn.o_proj.lora_A.default.weight', 'model.layers.5.self_attn.o_proj.lora_B.default.weight', 'model.layers.5.self_attn.qkv_proj.base_layer.weight', 'model.layers.5.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.5.self_attn.qkv_proj.lora_B.default.weight', 'model.layers.6.mlp.down_proj.base_layer.weight', 'model.layers.6.mlp.down_proj.lora_A.default.weight', 'model.layers.6.mlp.down_proj.lora_B.default.weight', 'model.layers.6.mlp.gate_up_proj.base_layer.weight', 'model.layers.6.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.6.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.6.self_attn.o_proj.base_layer.weight', 'model.layers.6.self_attn.o_proj.lora_A.default.weight', 'model.layers.6.self_attn.o_proj.lora_B.default.weight', 'model.layers.6.self_attn.qkv_proj.base_layer.weight', 'model.layers.6.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.6.self_attn.qkv_proj.lora_B.default.weight', 'model.layers.7.mlp.down_proj.base_layer.weight', 'model.layers.7.mlp.down_proj.lora_A.default.weight', 'model.layers.7.mlp.down_proj.lora_B.default.weight', 'model.layers.7.mlp.gate_up_proj.base_layer.weight', 'model.layers.7.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.7.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.7.self_attn.o_proj.base_layer.weight', 'model.layers.7.self_attn.o_proj.lora_A.default.weight', 'model.layers.7.self_attn.o_proj.lora_B.default.weight', 'model.layers.7.self_attn.qkv_proj.base_layer.weight', 'model.layers.7.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.7.self_attn.qkv_proj.lora_B.default.weight', 'model.layers.8.mlp.down_proj.base_layer.weight', 'model.layers.8.mlp.down_proj.lora_A.default.weight', 'model.layers.8.mlp.down_proj.lora_B.default.weight', 'model.layers.8.mlp.gate_up_proj.base_layer.weight', 'model.layers.8.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.8.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.8.self_attn.o_proj.base_layer.weight', 'model.layers.8.self_attn.o_proj.lora_A.default.weight', 'model.layers.8.self_attn.o_proj.lora_B.default.weight', 'model.layers.8.self_attn.qkv_proj.base_layer.weight', 'model.layers.8.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.8.self_attn.qkv_proj.lora_B.default.weight', 'model.layers.9.mlp.down_proj.base_layer.weight', 'model.layers.9.mlp.down_proj.lora_A.default.weight', 'model.layers.9.mlp.down_proj.lora_B.default.weight', 'model.layers.9.mlp.gate_up_proj.base_layer.weight', 'model.layers.9.mlp.gate_up_proj.lora_A.default.weight', 'model.layers.9.mlp.gate_up_proj.lora_B.default.weight', 'model.layers.9.self_attn.o_proj.base_layer.weight', 'model.layers.9.self_attn.o_proj.lora_A.default.weight', 'model.layers.9.self_attn.o_proj.lora_B.default.weight', 'model.layers.9.self_attn.qkv_proj.base_layer.weight', 'model.layers.9.self_attn.qkv_proj.lora_A.default.weight', 'model.layers.9.self_attn.qkv_proj.lora_B.default.weight']\n",
      "- This IS expected if you are initializing Phi3ForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Phi3ForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Phi3ForCausalLM were not initialized from the model checkpoint at ./trained_model and are newly initialized: ['model.layers.0.mlp.down_proj.weight', 'model.layers.0.mlp.gate_up_proj.weight', 'model.layers.0.self_attn.o_proj.weight', 'model.layers.0.self_attn.qkv_proj.weight', 'model.layers.1.mlp.down_proj.weight', 'model.layers.1.mlp.gate_up_proj.weight', 'model.layers.1.self_attn.o_proj.weight', 'model.layers.1.self_attn.qkv_proj.weight', 'model.layers.10.mlp.down_proj.weight', 'model.layers.10.mlp.gate_up_proj.weight', 'model.layers.10.self_attn.o_proj.weight', 'model.layers.10.self_attn.qkv_proj.weight', 'model.layers.11.mlp.down_proj.weight', 'model.layers.11.mlp.gate_up_proj.weight', 'model.layers.11.self_attn.o_proj.weight', 'model.layers.11.self_attn.qkv_proj.weight', 'model.layers.12.mlp.down_proj.weight', 'model.layers.12.mlp.gate_up_proj.weight', 'model.layers.12.self_attn.o_proj.weight', 'model.layers.12.self_attn.qkv_proj.weight', 'model.layers.13.mlp.down_proj.weight', 'model.layers.13.mlp.gate_up_proj.weight', 'model.layers.13.self_attn.o_proj.weight', 'model.layers.13.self_attn.qkv_proj.weight', 'model.layers.14.mlp.down_proj.weight', 'model.layers.14.mlp.gate_up_proj.weight', 'model.layers.14.self_attn.o_proj.weight', 'model.layers.14.self_attn.qkv_proj.weight', 'model.layers.15.mlp.down_proj.weight', 'model.layers.15.mlp.gate_up_proj.weight', 'model.layers.15.self_attn.o_proj.weight', 'model.layers.15.self_attn.qkv_proj.weight', 'model.layers.16.mlp.down_proj.weight', 'model.layers.16.mlp.gate_up_proj.weight', 'model.layers.16.self_attn.o_proj.weight', 'model.layers.16.self_attn.qkv_proj.weight', 'model.layers.17.mlp.down_proj.weight', 'model.layers.17.mlp.gate_up_proj.weight', 'model.layers.17.self_attn.o_proj.weight', 'model.layers.17.self_attn.qkv_proj.weight', 'model.layers.18.mlp.down_proj.weight', 'model.layers.18.mlp.gate_up_proj.weight', 'model.layers.18.self_attn.o_proj.weight', 'model.layers.18.self_attn.qkv_proj.weight', 'model.layers.19.mlp.down_proj.weight', 'model.layers.19.mlp.gate_up_proj.weight', 'model.layers.19.self_attn.o_proj.weight', 'model.layers.19.self_attn.qkv_proj.weight', 'model.layers.2.mlp.down_proj.weight', 'model.layers.2.mlp.gate_up_proj.weight', 'model.layers.2.self_attn.o_proj.weight', 'model.layers.2.self_attn.qkv_proj.weight', 'model.layers.20.mlp.down_proj.weight', 'model.layers.20.mlp.gate_up_proj.weight', 'model.layers.20.self_attn.o_proj.weight', 'model.layers.20.self_attn.qkv_proj.weight', 'model.layers.21.mlp.down_proj.weight', 'model.layers.21.mlp.gate_up_proj.weight', 'model.layers.21.self_attn.o_proj.weight', 'model.layers.21.self_attn.qkv_proj.weight', 'model.layers.22.mlp.down_proj.weight', 'model.layers.22.mlp.gate_up_proj.weight', 'model.layers.22.self_attn.o_proj.weight', 'model.layers.22.self_attn.qkv_proj.weight', 'model.layers.23.mlp.down_proj.weight', 'model.layers.23.mlp.gate_up_proj.weight', 'model.layers.23.self_attn.o_proj.weight', 'model.layers.23.self_attn.qkv_proj.weight', 'model.layers.24.mlp.down_proj.weight', 'model.layers.24.mlp.gate_up_proj.weight', 'model.layers.24.self_attn.o_proj.weight', 'model.layers.24.self_attn.qkv_proj.weight', 'model.layers.25.mlp.down_proj.weight', 'model.layers.25.mlp.gate_up_proj.weight', 'model.layers.25.self_attn.o_proj.weight', 'model.layers.25.self_attn.qkv_proj.weight', 'model.layers.26.mlp.down_proj.weight', 'model.layers.26.mlp.gate_up_proj.weight', 'model.layers.26.self_attn.o_proj.weight', 'model.layers.26.self_attn.qkv_proj.weight', 'model.layers.27.mlp.down_proj.weight', 'model.layers.27.mlp.gate_up_proj.weight', 'model.layers.27.self_attn.o_proj.weight', 'model.layers.27.self_attn.qkv_proj.weight', 'model.layers.28.mlp.down_proj.weight', 'model.layers.28.mlp.gate_up_proj.weight', 'model.layers.28.self_attn.o_proj.weight', 'model.layers.28.self_attn.qkv_proj.weight', 'model.layers.29.mlp.down_proj.weight', 'model.layers.29.mlp.gate_up_proj.weight', 'model.layers.29.self_attn.o_proj.weight', 'model.layers.29.self_attn.qkv_proj.weight', 'model.layers.3.mlp.down_proj.weight', 'model.layers.3.mlp.gate_up_proj.weight', 'model.layers.3.self_attn.o_proj.weight', 'model.layers.3.self_attn.qkv_proj.weight', 'model.layers.30.mlp.down_proj.weight', 'model.layers.30.mlp.gate_up_proj.weight', 'model.layers.30.self_attn.o_proj.weight', 'model.layers.30.self_attn.qkv_proj.weight', 'model.layers.31.mlp.down_proj.weight', 'model.layers.31.mlp.gate_up_proj.weight', 'model.layers.31.self_attn.o_proj.weight', 'model.layers.31.self_attn.qkv_proj.weight', 'model.layers.4.mlp.down_proj.weight', 'model.layers.4.mlp.gate_up_proj.weight', 'model.layers.4.self_attn.o_proj.weight', 'model.layers.4.self_attn.qkv_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.5.mlp.gate_up_proj.weight', 'model.layers.5.self_attn.o_proj.weight', 'model.layers.5.self_attn.qkv_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.6.mlp.gate_up_proj.weight', 'model.layers.6.self_attn.o_proj.weight', 'model.layers.6.self_attn.qkv_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.7.mlp.gate_up_proj.weight', 'model.layers.7.self_attn.o_proj.weight', 'model.layers.7.self_attn.qkv_proj.weight', 'model.layers.8.mlp.down_proj.weight', 'model.layers.8.mlp.gate_up_proj.weight', 'model.layers.8.self_attn.o_proj.weight', 'model.layers.8.self_attn.qkv_proj.weight', 'model.layers.9.mlp.down_proj.weight', 'model.layers.9.mlp.gate_up_proj.weight', 'model.layers.9.self_attn.o_proj.weight', 'model.layers.9.self_attn.qkv_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T20:20:02.682924Z",
     "start_time": "2024-11-27T20:20:00.557711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(model, \"checkpoint_dir/checkpoint-120\")\n",
    "peft_model.eval()"
   ],
   "id": "2d442f40c9fdd801",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Phi3ForCausalLM(\n",
       "      (model): Phi3Model(\n",
       "        (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n",
       "        (embed_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x Phi3DecoderLayer(\n",
       "            (self_attn): Phi3SdpaAttention(\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (qkv_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3072, out_features=9216, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=9216, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): Phi3RotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Phi3MLP(\n",
       "              (gate_up_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3072, out_features=16384, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=16384, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=8192, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (activation_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "            (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (post_attention_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T22:12:12.702493Z",
     "start_time": "2024-11-26T22:12:12.697527Z"
    }
   },
   "cell_type": "code",
   "source": "test_sentence = '<|system|>\\nPlease identify all the named entities mentioned in the input sentence provided below. Use only the categories: SpecificDisease, DiseaseClass, CompositeMention, and Modifier. Remember, some terms might refer to broader disease classes, while others are specific diseases or composite mentions involving multiple diseases. You should only output the results in JSON format, following a similar structure to the example result provided.\\n\\nExample sentence and results:\\n\"A common human skin tumour is caused by activating mutations in beta-catenin.\"\\n\\n\"Results\": [\\n{ \"category\": \"DiseaseClass\", \"entity\": \"skin tumour\" }\\n]\\n<|end|>\\n<|user|>\\nSomatic-cell selection is a major determinant of the blood-cell phenotype in heterozygotes for glucose-6-phosphate dehydrogenase mutations causing severe enzyme deficiency.X-chromosome inactivation in mammals is regarded as an essentially random process, but the resulting somatic-cell mosaicism creates the opportunity for cell selection.<|end|>\\n<|assistant|>\\n'",
   "id": "3e1c23833fbcdb7b",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T22:21:11.676506800Z",
     "start_time": "2024-11-26T22:19:51.151371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from outlines import generate\n",
    "\n",
    "test_mod = models.Transformers(model, tokenizer)\n",
    "generator = generate.regex(test_mod, entity_arr_regex)\n",
    "generator(test_sentence)"
   ],
   "id": "546077ec23772efc",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[58], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m test_mod \u001B[38;5;241m=\u001B[39m models\u001B[38;5;241m.\u001B[39mTransformers(model, tokenizer)\n\u001B[1;32m      4\u001B[0m generator \u001B[38;5;241m=\u001B[39m generate\u001B[38;5;241m.\u001B[39mregex(test_mod, entity_arr_regex)\n\u001B[0;32m----> 5\u001B[0m \u001B[43mgenerator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_sentence\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/outlines/generate/api.py:504\u001B[0m, in \u001B[0;36mSequenceGeneratorAdapter.__call__\u001B[0;34m(self, prompts, max_tokens, stop_at, seed, **model_specific_params)\u001B[0m\n\u001B[1;32m    498\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Generate text from a prompt of list of prompts.\"\"\"\u001B[39;00m\n\u001B[1;32m    500\u001B[0m generation_params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_generation_parameters(\n\u001B[1;32m    501\u001B[0m     max_tokens, stop_at, seed\n\u001B[1;32m    502\u001B[0m )\n\u001B[0;32m--> 504\u001B[0m completions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    505\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprompts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    506\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgeneration_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    507\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlogits_processor\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    508\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msampling_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    509\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_specific_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    510\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    512\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format(completions)\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/outlines/models/transformers.py:247\u001B[0m, in \u001B[0;36mTransformers.generate\u001B[0;34m(self, prompts, generation_parameters, logits_processor, sampling_parameters)\u001B[0m\n\u001B[1;32m    239\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m inputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    241\u001B[0m generation_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_generation_kwargs(\n\u001B[1;32m    242\u001B[0m     prompts,\n\u001B[1;32m    243\u001B[0m     generation_parameters,\n\u001B[1;32m    244\u001B[0m     logits_processor,\n\u001B[1;32m    245\u001B[0m     sampling_parameters,\n\u001B[1;32m    246\u001B[0m )\n\u001B[0;32m--> 247\u001B[0m generated_ids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate_output_seq\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mgeneration_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;66;03m# if single str input and single sample per input, convert to a 1D output\u001B[39;00m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(prompts, \u001B[38;5;28mstr\u001B[39m):\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/outlines/models/transformers.py:350\u001B[0m, in \u001B[0;36mTransformers._generate_output_seq\u001B[0;34m(self, prompts, inputs, generation_config, **generation_kwargs)\u001B[0m\n\u001B[1;32m    346\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_generate_output_seq\u001B[39m(\n\u001B[1;32m    347\u001B[0m     \u001B[38;5;28mself\u001B[39m, prompts, inputs, generation_config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mgeneration_kwargs\n\u001B[1;32m    348\u001B[0m ):\n\u001B[1;32m    349\u001B[0m     input_ids \u001B[38;5;241m=\u001B[39m inputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m--> 350\u001B[0m     output_ids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    351\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mgeneration_kwargs\u001B[49m\n\u001B[1;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    354\u001B[0m     \u001B[38;5;66;03m# encoder-decoder returns output_ids only, decoder-only returns full seq ids\u001B[39;00m\n\u001B[1;32m    355\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder:\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    115\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 116\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/transformers/generation/utils.py:2215\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001B[0m\n\u001B[1;32m   2207\u001B[0m     input_ids, model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expand_inputs_for_generation(\n\u001B[1;32m   2208\u001B[0m         input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m   2209\u001B[0m         expand_size\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_return_sequences,\n\u001B[1;32m   2210\u001B[0m         is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[1;32m   2211\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   2212\u001B[0m     )\n\u001B[1;32m   2214\u001B[0m     \u001B[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001B[39;00m\n\u001B[0;32m-> 2215\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sample\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2216\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2217\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlogits_processor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_logits_processor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2218\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstopping_criteria\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_stopping_criteria\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2219\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2220\u001B[0m \u001B[43m        \u001B[49m\u001B[43msynced_gpus\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msynced_gpus\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2221\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstreamer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstreamer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2222\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2223\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2225\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m generation_mode \u001B[38;5;129;01min\u001B[39;00m (GenerationMode\u001B[38;5;241m.\u001B[39mBEAM_SAMPLE, GenerationMode\u001B[38;5;241m.\u001B[39mBEAM_SEARCH):\n\u001B[1;32m   2226\u001B[0m     \u001B[38;5;66;03m# 11. prepare beam search scorer\u001B[39;00m\n\u001B[1;32m   2227\u001B[0m     beam_scorer \u001B[38;5;241m=\u001B[39m BeamSearchScorer(\n\u001B[1;32m   2228\u001B[0m         batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m   2229\u001B[0m         num_beams\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_beams,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2234\u001B[0m         max_length\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mmax_length,\n\u001B[1;32m   2235\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/transformers/generation/utils.py:3223\u001B[0m, in \u001B[0;36mGenerationMixin._sample\u001B[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001B[0m\n\u001B[1;32m   3220\u001B[0m next_token_logits \u001B[38;5;241m=\u001B[39m next_token_logits\u001B[38;5;241m.\u001B[39mto(input_ids\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m   3222\u001B[0m \u001B[38;5;66;03m# pre-process distribution\u001B[39;00m\n\u001B[0;32m-> 3223\u001B[0m next_token_scores \u001B[38;5;241m=\u001B[39m \u001B[43mlogits_processor\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnext_token_logits\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3225\u001B[0m \u001B[38;5;66;03m# Store scores, attentions and hidden_states when required\u001B[39;00m\n\u001B[1;32m   3226\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m return_dict_in_generate:\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/transformers/generation/logits_process.py:104\u001B[0m, in \u001B[0;36mLogitsProcessorList.__call__\u001B[0;34m(self, input_ids, scores, **kwargs)\u001B[0m\n\u001B[1;32m    102\u001B[0m         scores \u001B[38;5;241m=\u001B[39m processor(input_ids, scores, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    103\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 104\u001B[0m         scores \u001B[38;5;241m=\u001B[39m \u001B[43mprocessor\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscores\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    106\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m scores\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    115\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 116\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/outlines/processors/base_logits_processor.py:78\u001B[0m, in \u001B[0;36mOutlinesLogitsProcessor.__call__\u001B[0;34m(self, input_ids, logits)\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;66;03m# Guarantee passed as 2D Tensors, then covert back to original (1D or 2D) shape\u001B[39;00m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(torch_logits\u001B[38;5;241m.\u001B[39mshape) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[0;32m---> 78\u001B[0m     processed_logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess_logits\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch_logits\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     79\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(torch_logits\u001B[38;5;241m.\u001B[39mshape) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m     80\u001B[0m     processed_logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_logits(\n\u001B[1;32m     81\u001B[0m         input_ids\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m), torch_logits\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     82\u001B[0m     )\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/outlines/processors/structured.py:96\u001B[0m, in \u001B[0;36mGuideLogitsProcessor.process_logits\u001B[0;34m(self, input_ids, logits)\u001B[0m\n\u001B[1;32m     94\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m seq_ids \u001B[38;5;129;01min\u001B[39;00m input_ids:\n\u001B[1;32m     95\u001B[0m     gen_ids \u001B[38;5;241m=\u001B[39m seq_ids[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_seq_start_idx :]\n\u001B[0;32m---> 96\u001B[0m     curr_state_key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mhash\u001B[39m(\u001B[38;5;28mtuple\u001B[39m(\u001B[43mgen_ids\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtolist\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m))\n\u001B[1;32m     98\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m curr_state_key \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_guide_states:\n\u001B[1;32m     99\u001B[0m         prev_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_guide_states[\u001B[38;5;28mhash\u001B[39m(\u001B[38;5;28mtuple\u001B[39m(gen_ids[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mtolist()))]\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T22:26:34.426141Z",
     "start_time": "2024-11-26T22:26:34.393217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import openai\n",
    "from litellm import completion\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "litellm_url = \"http://147.175.151.44/\"\n",
    "model = \"gpt-4o-mini\"\n",
    "client = openai.OpenAI(api_key=api_key, base_url=litellm_url)"
   ],
   "id": "f0d5814f00360d74",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T22:31:44.022780Z",
     "start_time": "2024-11-26T22:31:44.018169Z"
    }
   },
   "cell_type": "code",
   "source": "openai_model = models.openai(client, config=None)",
   "id": "940cc0763a1ee0c9",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T22:32:59.769894Z",
     "start_time": "2024-11-26T22:32:59.740365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "openai_generator = generate.json(openai_model, json.dump(json_schema))\n",
    "#openai_generator(test_sentence)"
   ],
   "id": "52854741376b0b5c",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot parse schema {'$defs': {'Category': {'enum': ['SpecificDisease', 'DiseaseClass', 'Modifier', 'CompositeMention'], 'title': 'Category', 'type': 'string'}}, 'properties': {'category': {'$ref': '#/$defs/Category'}, 'entity': {'title': 'Entity', 'type': 'string'}}, 'required': ['category', 'entity'], 'title': 'Entity', 'type': 'object'}. The schema must be either a Pydantic object, a function or a string that contains the JSON Schema specification",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[69], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m openai_generator \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjson\u001B[49m\u001B[43m(\u001B[49m\u001B[43mopenai_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjson_schema\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#openai_generator(test_sentence)\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/functools.py:907\u001B[0m, in \u001B[0;36msingledispatch.<locals>.wrapper\u001B[0;34m(*args, **kw)\u001B[0m\n\u001B[1;32m    903\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m args:\n\u001B[1;32m    904\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfuncname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires at least \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    905\u001B[0m                     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m1 positional argument\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m--> 907\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__class__\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/outlines/generate/json.py:88\u001B[0m, in \u001B[0;36mjson_openai\u001B[0;34m(model, schema_object, sampler)\u001B[0m\n\u001B[1;32m     86\u001B[0m     format_sequence \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m x: pyjson\u001B[38;5;241m.\u001B[39mloads(x)\n\u001B[1;32m     87\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 88\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m     89\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot parse schema \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mschema_object\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. The schema must be either \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     90\u001B[0m         \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma Pydantic object, a function or a string that contains the JSON \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     91\u001B[0m         \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSchema specification\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     92\u001B[0m     )\n\u001B[1;32m     94\u001B[0m \u001B[38;5;66;03m# create copied, patched model with normalized json schema set\u001B[39;00m\n\u001B[1;32m     95\u001B[0m generator \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mnew_with_replacements(\n\u001B[1;32m     96\u001B[0m     response_format\u001B[38;5;241m=\u001B[39m{\n\u001B[1;32m     97\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjson_schema\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    103\u001B[0m     }\n\u001B[1;32m    104\u001B[0m )\n",
      "\u001B[0;31mValueError\u001B[0m: Cannot parse schema {'$defs': {'Category': {'enum': ['SpecificDisease', 'DiseaseClass', 'Modifier', 'CompositeMention'], 'title': 'Category', 'type': 'string'}}, 'properties': {'category': {'$ref': '#/$defs/Category'}, 'entity': {'title': 'Entity', 'type': 'string'}}, 'required': ['category', 'entity'], 'title': 'Entity', 'type': 'object'}. The schema must be either a Pydantic object, a function or a string that contains the JSON Schema specification"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Apply outlines coalescence to the tokenizer",
   "id": "7537b826fa0b5e62"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First, we need to add attribute vocabulary, which is required by outlines, as LlamaTokenizer's vocabulary is named vocab.",
   "id": "2e0b9a41e1e88cfa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T21:49:09.153970Z",
     "start_time": "2024-11-26T21:49:09.138436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not hasattr(tokenizer, \"vocabulary\"):\n",
    "    @property\n",
    "    def vocabulary(self):\n",
    "        return self.vocab\n",
    "    setattr(tokenizer, \"vocabulary\", vocabulary)\n",
    "\n",
    "if not hasattr(tokenizer, \"special_tokens\") and hasattr(tokenizer, \"special_tokens_map\"):\n",
    "    setattr(tokenizer, \"special_tokens\", tokenizer.special_tokens_map.values())\n",
    "    \n",
    "if not hasattr(tokenizer, \"convert_token_to_string\"):\n",
    "    setattr(tokenizer, \"convert_token_to_string\", lambda x: tokenizer.convert_tokens_to_ids([x]))\n"
   ],
   "id": "2a8d2fd08ebfa0f4",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T21:49:09.126741Z",
     "start_time": "2024-11-26T21:49:11.170653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from outlines_core.fsm.regex import make_deterministic_fsm, create_fsm_index_tokenizer\n",
    "import interegular\n",
    "\n",
    "parsed_pattern = interegular.patterns.parse_pattern(entity_arr_regex)\n",
    "fsm = parsed_pattern.to_fsm()\n",
    "new_fsm, _ = make_deterministic_fsm(fsm)\n",
    "# doesn't work as LlamaTokenizer \n",
    "index, _ = create_fsm_index_tokenizer(new_fsm, tokenizer)"
   ],
   "id": "711e5b4539804230",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[37], line 8\u001B[0m\n\u001B[1;32m      6\u001B[0m new_fsm, _ \u001B[38;5;241m=\u001B[39m make_deterministic_fsm(fsm)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# doesn't work as LlamaTokenizer \u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m index, _ \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_fsm_index_tokenizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnew_fsm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/outlines_core/fsm/regex.py:471\u001B[0m, in \u001B[0;36mcreate_fsm_index_tokenizer\u001B[0;34m(fsm, tokenizer, frozen_tokens)\u001B[0m\n\u001B[1;32m    438\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate_fsm_index_tokenizer\u001B[39m(\n\u001B[1;32m    439\u001B[0m     fsm: BetterFSM,\n\u001B[1;32m    440\u001B[0m     tokenizer,\n\u001B[1;32m    441\u001B[0m     frozen_tokens: Optional[Iterable[\u001B[38;5;28mstr\u001B[39m]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    442\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Index, Set[\u001B[38;5;28mint\u001B[39m]]:\n\u001B[1;32m    443\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Construct an FMS index from a tokenizer.\u001B[39;00m\n\u001B[1;32m    444\u001B[0m \n\u001B[1;32m    445\u001B[0m \u001B[38;5;124;03m    This uses the end-to-end approach of `create_fsm_index_end_to_end`.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    469\u001B[0m \u001B[38;5;124;03m        `fsm` needs to be deterministically ordered so that future caching makes sense.\u001B[39;00m\n\u001B[1;32m    470\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 471\u001B[0m     tokens_to_token_ids, empty_token_ids \u001B[38;5;241m=\u001B[39m \u001B[43mreduced_vocabulary\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    473\u001B[0m     states_to_token_subsets \u001B[38;5;241m=\u001B[39m Index(  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m    474\u001B[0m         fsm\u001B[38;5;241m.\u001B[39mfsm_info,\n\u001B[1;32m    475\u001B[0m         Vocabulary\u001B[38;5;241m.\u001B[39mfrom_dict(tokens_to_token_ids),\n\u001B[1;32m    476\u001B[0m         tokenizer\u001B[38;5;241m.\u001B[39meos_token_id,\n\u001B[1;32m    477\u001B[0m         \u001B[38;5;28mfrozenset\u001B[39m(frozen_tokens) \u001B[38;5;28;01mif\u001B[39;00m frozen_tokens \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mfrozenset\u001B[39m(),\n\u001B[1;32m    478\u001B[0m     )\n\u001B[1;32m    480\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m states_to_token_subsets, empty_token_ids\n",
      "File \u001B[0;32m~/anaconda3/envs/bp/lib/python3.12/site-packages/outlines_core/fsm/regex.py:396\u001B[0m, in \u001B[0;36mreduced_vocabulary\u001B[0;34m(tokenizer)\u001B[0m\n\u001B[1;32m    393\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m token \u001B[38;5;129;01min\u001B[39;00m tokenizer\u001B[38;5;241m.\u001B[39mspecial_tokens:\n\u001B[1;32m    394\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m--> 396\u001B[0m token_str: Union[\u001B[38;5;28mstr\u001B[39m, Tuple[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m]] \u001B[38;5;241m=\u001B[39m \u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_token_to_string\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    397\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken\u001B[49m\n\u001B[1;32m    398\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    400\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m token_str:\n\u001B[1;32m    401\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(token, \u001B[38;5;28mbytes\u001B[39m):\n\u001B[1;32m    402\u001B[0m         \u001B[38;5;66;03m# Handle BPE tokenizers where the tokens are directly stored as bytes\u001B[39;00m\n\u001B[1;32m    403\u001B[0m         \u001B[38;5;66;03m# https://github.com/QwenLM/Qwen/blob/main/tokenization_note.md#regular-tokens\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[29], line 11\u001B[0m, in \u001B[0;36m<lambda>\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;28msetattr\u001B[39m(tokenizer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mspecial_tokens\u001B[39m\u001B[38;5;124m\"\u001B[39m, tokenizer\u001B[38;5;241m.\u001B[39mspecial_tokens_map\u001B[38;5;241m.\u001B[39mvalues())\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(tokenizer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconvert_token_to_string\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m---> 11\u001B[0m     \u001B[38;5;28msetattr\u001B[39m(tokenizer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconvert_token_to_string\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_tokens_to_ids\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m)\n",
      "\u001B[0;31mTypeError\u001B[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T21:42:17.182427Z",
     "start_time": "2024-11-26T21:42:17.174024Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.special_tokens_map",
   "id": "e1315374e13a2c8a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<s>',\n",
       " 'eos_token': '<|endoftext|>',\n",
       " 'unk_token': '<unk>',\n",
       " 'pad_token': '<unk>'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T17:31:11.656614Z",
     "start_time": "2024-11-26T17:31:11.621526Z"
    }
   },
   "cell_type": "code",
   "source": "ol_model = models.Transformers(model, tokenizer)",
   "id": "12498c6c7c2127bb",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "385898317b71d818"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
